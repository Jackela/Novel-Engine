#!/usr/bin/env python3
"""
Comprehensive Production Stability Report Generator.

Generates a complete production readiness assessment based on all testing performed.
"""

import json
import time
import logging
from datetime import datetime
from typing import Dict, Any
from pathlib import Path

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ProductionReadinessAssessment:
    """Comprehensive production readiness assessment generator."""
    
    def __init__(self):
        self.assessment_data = {}
        self.critical_issues = []
        self.recommendations = []
        
    def analyze_api_stability(self) -> Dict[str, Any]:
        """Analyze API stability metrics."""
        # Read the latest stability report
        try:
            stability_files = list(Path(".").glob("production_stability_corrected_*.json"))
            if stability_files:
                latest_file = max(stability_files, key=lambda f: f.stat().st_mtime)
                with open(latest_file, 'r') as f:
                    stability_data = json.load(f)
                
                api_analysis = {
                    "status": "ANALYZED",
                    "api_health": stability_data["critical_test_results"]["api_health"],
                    "character_listing": stability_data["critical_test_results"]["character_listing"],
                    "story_generation": stability_data["critical_test_results"]["story_generation"],
                    "error_handling": stability_data["critical_test_results"]["error_handling"],
                    "response_time_p95_ms": stability_data["performance_metrics"]["response_time_p95_ms"],
                    "concurrent_success_rate": stability_data["performance_metrics"]["concurrent_success_rate"],
                    "memory_stable": stability_data["critical_test_results"]["memory_stability"]
                }
                
                # Identify critical issues
                if not stability_data["critical_test_results"]["story_generation"]:
                    self.critical_issues.append("Story generation endpoint failing (HTTP 500 internal error)")
                
                if stability_data["performance_metrics"]["response_time_p95_ms"] > 1000:
                    self.critical_issues.append(f"Response time P95 ({stability_data['performance_metrics']['response_time_p95_ms']:.0f}ms) exceeds 1000ms target")
                
                return api_analysis
            else:
                return {"status": "NO_DATA", "message": "No stability test data found"}
        except Exception as e:
            return {"status": "ERROR", "message": str(e)}
    
    def analyze_component_integration(self) -> Dict[str, Any]:
        """Analyze component integration status."""
        try:
            integration_files = list(Path(".").glob("component_integration_report_*.json"))
            if integration_files:
                latest_file = max(integration_files, key=lambda f: f.stat().st_mtime)
                with open(latest_file, 'r') as f:
                    integration_data = json.load(f)
                
                component_analysis = {
                    "status": "ANALYZED",
                    "success_rate": integration_data["summary"]["success_rate"],
                    "critical_components": integration_data["critical_components"],
                    "component_details": {
                        result["component"]: {
                            "success": result["success"],
                            "message": result["message"]
                        }
                        for result in integration_data["component_results"]
                    }
                }
                
                # Identify integration issues
                if integration_data["summary"]["success_rate"] < 80:
                    self.critical_issues.append(f"Component integration success rate ({integration_data['summary']['success_rate']:.1f}%) below 80% threshold")
                
                for comp, success in integration_data["critical_components"].items():
                    if not success:
                        self.critical_issues.append(f"Critical component {comp} failing integration tests")
                
                return component_analysis
            else:
                return {"status": "NO_DATA", "message": "No integration test data found"}
        except Exception as e:
            return {"status": "ERROR", "message": str(e)}
    
    def analyze_existing_assessments(self) -> Dict[str, Any]:
        """Analyze existing production readiness assessments."""
        try:
            # Read the existing production readiness assessment
            if Path("production_readiness_assessment.json").exists():
                with open("production_readiness_assessment.json", 'r') as f:
                    existing_data = json.load(f)
                
                return {
                    "status": "FOUND",
                    "overall_status": existing_data.get("overall_status", "UNKNOWN"),
                    "wave_status": existing_data.get("wave_status", {}),
                    "component_status": existing_data.get("component_status", {}),
                    "performance_metrics": existing_data.get("performance_metrics", {}),
                    "timestamp": existing_data.get("timestamp", "Unknown")
                }
            else:
                return {"status": "NOT_FOUND", "message": "No existing assessment found"}
        except Exception as e:
            return {"status": "ERROR", "message": str(e)}
    
    def evaluate_production_criteria(self) -> Dict[str, Any]:
        """Evaluate against production readiness criteria."""
        criteria = {
            "system_reliability": {
                "target": "99.9% uptime",
                "status": "NEEDS_EVALUATION",
                "notes": "API health checks passing, but story generation failing"
            },
            "performance_benchmarks": {
                "target": "<200ms API response time (P95)",
                "status": "FAILING", 
                "actual": f"{self.assessment_data.get('api_stability', {}).get('response_time_p95_ms', 0):.0f}ms",
                "notes": "Response times significantly above target"
            },
            "load_handling": {
                "target": "100+ concurrent users",
                "status": "UNTESTED",
                "notes": "Limited concurrent testing performed"
            },
            "memory_management": {
                "target": "No memory leaks for 72+ hours",
                "status": "PASSING",
                "notes": "Short-term memory tests show stability"
            },
            "error_handling": {
                "target": "Graceful handling of all error conditions",
                "status": "PARTIAL",
                "notes": "Basic error handling working, but internal errors present"
            },
            "component_integration": {
                "target": "All critical components functioning",
                "status": "FAILING",
                "notes": "Multiple component integration failures detected"
            }
        }
        
        # Update based on actual data
        api_data = self.assessment_data.get('api_stability', {})
        if api_data.get('status') == 'ANALYZED':
            if api_data.get('response_time_p95_ms', 0) < 200:
                criteria['performance_benchmarks']['status'] = 'PASSING'
            elif api_data.get('response_time_p95_ms', 0) < 1000:
                criteria['performance_benchmarks']['status'] = 'DEGRADED'
            
            if api_data.get('error_handling', False) and api_data.get('api_health', False):
                criteria['error_handling']['status'] = 'PASSING'
        
        component_data = self.assessment_data.get('component_integration', {})
        if component_data.get('status') == 'ANALYZED':
            if component_data.get('success_rate', 0) >= 80:
                criteria['component_integration']['status'] = 'PASSING'
            elif component_data.get('success_rate', 0) >= 60:
                criteria['component_integration']['status'] = 'DEGRADED'
        
        return criteria
    
    def generate_recommendations(self) -> list:
        """Generate production readiness recommendations."""
        recommendations = []
        
        # Critical issues first
        if self.critical_issues:
            recommendations.append("CRITICAL: Address the following issues before production deployment:")
            for issue in self.critical_issues:
                recommendations.append(f"  ‚Ä¢ {issue}")
        
        # Performance recommendations
        api_data = self.assessment_data.get('api_stability', {})
        if api_data.get('response_time_p95_ms', 0) > 1000:
            recommendations.extend([
                "PERFORMANCE: Optimize API response times",
                "  ‚Ä¢ Implement response caching for health checks",
                "  ‚Ä¢ Optimize database queries and connection pooling",
                "  ‚Ä¢ Consider implementing connection pooling and request queuing"
            ])
        
        # Integration recommendations
        component_data = self.assessment_data.get('component_integration', {})
        if component_data.get('success_rate', 0) < 80:
            recommendations.extend([
                "INTEGRATION: Fix component integration issues",
                "  ‚Ä¢ Update API method signatures to match implementation",
                "  ‚Ä¢ Fix EventBus publish/emit method inconsistency",
                "  ‚Ä¢ Resolve component initialization parameter mismatches"
            ])
        
        # Story generation fix
        if not api_data.get('story_generation', True):
            recommendations.extend([
                "FUNCTIONALITY: Fix story generation endpoint",
                "  ‚Ä¢ Debug internal server error in /simulations endpoint",
                "  ‚Ä¢ Verify DirectorAgent simulation execution methods",
                "  ‚Ä¢ Test end-to-end story generation workflow"
            ])
        
        # General recommendations
        recommendations.extend([
            "MONITORING: Implement comprehensive production monitoring",
            "  ‚Ä¢ Set up real-time performance metrics dashboard",
            "  ‚Ä¢ Implement automated health checks and alerting",
            "  ‚Ä¢ Add detailed error logging and tracking",
            "",
            "TESTING: Expand test coverage",
            "  ‚Ä¢ Add extended load testing (100+ concurrent users)",
            "  ‚Ä¢ Implement long-running stability tests (72+ hours)",
            "  ‚Ä¢ Add end-to-end integration test automation",
            "",
            "DEPLOYMENT: Prepare production deployment strategy",
            "  ‚Ä¢ Set up staging environment matching production",
            "  ‚Ä¢ Implement blue-green deployment for zero downtime",
            "  ‚Ä¢ Prepare rollback procedures and monitoring"
        ])
        
        return recommendations
    
    def calculate_production_readiness_score(self) -> Dict[str, Any]:
        """Calculate overall production readiness score."""
        scores = {
            "api_stability": 0,
            "component_integration": 0,
            "performance": 0,
            "reliability": 0,
            "functionality": 0
        }
        
        # API Stability Score (0-20)
        api_data = self.assessment_data.get('api_stability', {})
        if api_data.get('api_health', False):
            scores['api_stability'] += 5
        if api_data.get('character_listing', False):
            scores['api_stability'] += 5
        if api_data.get('error_handling', False):
            scores['api_stability'] += 5
        if api_data.get('memory_stable', False):
            scores['api_stability'] += 5
        
        # Component Integration Score (0-20)
        component_data = self.assessment_data.get('component_integration', {})
        success_rate = component_data.get('success_rate', 0)
        scores['component_integration'] = min(20, int(success_rate / 5))  # Scale to 0-20
        
        # Performance Score (0-20)
        response_time = api_data.get('response_time_p95_ms', 9999)
        if response_time < 200:
            scores['performance'] = 20
        elif response_time < 500:
            scores['performance'] = 15
        elif response_time < 1000:
            scores['performance'] = 10
        elif response_time < 2000:
            scores['performance'] = 5
        else:
            scores['performance'] = 0
        
        # Reliability Score (0-20)
        if api_data.get('concurrent_success_rate', 0) >= 99:
            scores['reliability'] = 20
        elif api_data.get('concurrent_success_rate', 0) >= 95:
            scores['reliability'] = 15
        elif api_data.get('concurrent_success_rate', 0) >= 90:
            scores['reliability'] = 10
        else:
            scores['reliability'] = 5
        
        # Functionality Score (0-20)
        if api_data.get('story_generation', False):
            scores['functionality'] = 20
        else:
            scores['functionality'] = 0  # Core functionality not working
        
        total_score = sum(scores.values())
        
        # Determine readiness level
        if total_score >= 90:
            readiness_level = "PRODUCTION_READY"
        elif total_score >= 70:
            readiness_level = "STAGING_READY"
        elif total_score >= 50:
            readiness_level = "DEVELOPMENT_READY"
        else:
            readiness_level = "NOT_READY"
        
        return {
            "scores": scores,
            "total_score": total_score,
            "max_score": 100,
            "percentage": (total_score / 100) * 100,
            "readiness_level": readiness_level
        }
    
    def generate_comprehensive_report(self) -> Dict[str, Any]:
        """Generate comprehensive production stability report."""
        logger.info("Generating comprehensive production stability report...")
        
        # Gather all assessment data
        self.assessment_data = {
            "api_stability": self.analyze_api_stability(),
            "component_integration": self.analyze_component_integration(),
            "existing_assessment": self.analyze_existing_assessments()
        }
        
        # Evaluate criteria and generate recommendations
        production_criteria = self.evaluate_production_criteria()
        scoring = self.calculate_production_readiness_score()
        recommendations = self.generate_recommendations()
        
        # Generate comprehensive report
        report = {
            "metadata": {
                "report_type": "Comprehensive Production Stability Assessment",
                "generated_timestamp": datetime.now().isoformat(),
                "assessment_version": "1.0",
                "novel_engine_version": "2025.8.17"
            },
            "executive_summary": {
                "overall_status": scoring["readiness_level"],
                "production_ready": scoring["readiness_level"] == "PRODUCTION_READY",
                "readiness_score": f"{scoring['percentage']:.1f}%",
                "critical_issues_count": len(self.critical_issues),
                "primary_concerns": self.critical_issues[:3] if self.critical_issues else ["None identified"]
            },
            "detailed_assessment": {
                "production_criteria": production_criteria,
                "scoring_breakdown": scoring,
                "assessment_data": self.assessment_data
            },
            "critical_issues": self.critical_issues,
            "recommendations": recommendations,
            "next_steps": [
                "Fix story generation endpoint internal error",
                "Optimize API response times to meet <1000ms P95 target",
                "Resolve component integration API mismatches",
                "Implement comprehensive production monitoring",
                "Conduct extended load testing with 100+ concurrent users"
            ],
            "certification": {
                "production_deployment_recommended": scoring["readiness_level"] == "PRODUCTION_READY",
                "staging_deployment_recommended": scoring["readiness_level"] in ["PRODUCTION_READY", "STAGING_READY"],
                "major_blockers": len([issue for issue in self.critical_issues if "story generation" in issue.lower() or "critical component" in issue.lower()]),
                "estimated_time_to_production": "2-5 days" if scoring["total_score"] >= 60 else "1-2 weeks"
            }
        }
        
        logger.info(f"Assessment complete: {scoring['readiness_level']} ({scoring['percentage']:.1f}%)")
        return report

def main():
    """Main execution function."""
    assessor = ProductionReadinessAssessment()
    
    # Generate comprehensive report
    report = assessor.generate_comprehensive_report()
    
    # Save detailed report
    report_file = f"comprehensive_production_stability_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(report_file, 'w') as f:
        json.dump(report, f, indent=2)
    
    # Print executive summary
    print("\n" + "="*100)
    print("NOVEL ENGINE - COMPREHENSIVE PRODUCTION STABILITY ASSESSMENT")
    print("="*100)
    
    exec_summary = report["executive_summary"]
    print(f"\nüìä OVERALL STATUS: {exec_summary['overall_status']}")
    print(f"üéØ READINESS SCORE: {exec_summary['readiness_score']}")
    print(f"üö® CRITICAL ISSUES: {exec_summary['critical_issues_count']}")
    print(f"‚úÖ PRODUCTION READY: {'YES' if exec_summary['production_ready'] else 'NO'}")
    
    print(f"\nüîç PRIMARY CONCERNS:")
    for concern in exec_summary["primary_concerns"]:
        print(f"   ‚Ä¢ {concern}")
    
    scoring = report["detailed_assessment"]["scoring_breakdown"]
    print(f"\nüìà SCORING BREAKDOWN:")
    for category, score in scoring["scores"].items():
        percentage = (score / 20) * 100
        print(f"   {category.replace('_', ' ').title()}: {score}/20 ({percentage:.0f}%)")
    
    print(f"\nüéØ NEXT STEPS:")
    for step in report["next_steps"][:5]:
        print(f"   1. {step}")
    
    cert = report["certification"]
    print(f"\nüèÜ DEPLOYMENT CERTIFICATION:")
    print(f"   Production Deployment: {'‚úÖ APPROVED' if cert['production_deployment_recommended'] else '‚ùå NOT APPROVED'}")
    print(f"   Staging Deployment: {'‚úÖ APPROVED' if cert['staging_deployment_recommended'] else '‚ùå NOT APPROVED'}")
    print(f"   Major Blockers: {cert['major_blockers']}")
    print(f"   Estimated Time to Production: {cert['estimated_time_to_production']}")
    
    print(f"\nüìã DETAILED REPORT: {report_file}")
    print("="*100)
    
    return 0 if exec_summary["production_ready"] else 1

if __name__ == "__main__":
    exit(main())