# AI Novel Generation System - Project Goals & Architecture

## üö® CURRENT STATUS: MAJOR REFACTOR IN PROGRESS
**Transitioning from template-based fake AI to genuine LLM-powered system**

## Project Vision
Build a **genuine AI-powered novel generation system** using Large Language Models (LLMs) for dynamic, creative content generation.

## ‚ö° IMMEDIATE MISSION
**Phase 1 (This Week)**: Remove all template-based fake AI systems
**Phase 2 (Next Week)**: Implement real LLM-driven generation
**Phase 3 (Following Week)**: Establish authentic quality metrics

## Core Principles

### What This Project IS
- **LLM-Driven Generation**: All content generated by AI models (Gemini 2.0 Flash primary)
- **Character-Aware**: Generation based on dynamic personality vectors
- **Context-Sensitive**: Story coherence through context management
- **Genuinely Creative**: Unique outputs, never template selection

### What This Project IS NOT
- ‚ùå Template/Pattern matching system
- ‚ùå Random selection from predefined content  
- ‚ùå N-gram based "creativity" metrics
- ‚ùå Hardcoded dialogue or event libraries

## Technical Architecture (NEW)

### Core Structure
```
ai_testing/
‚îú‚îÄ‚îÄ core/           # LLM integration and orchestration
‚îú‚îÄ‚îÄ models/         # Data models and state management
‚îú‚îÄ‚îÄ generators/     # AI-powered content generators
‚îú‚îÄ‚îÄ quality/        # Real quality metrics and enhancement
‚îî‚îÄ‚îÄ legacy/         # Archived template systems
```

### LLM Integration
```python
class LLMClient:
    # Gemini 2.0 Flash (primary)
    # OpenAI GPT-4 (fallback)
    # Anthropic Claude (alternative)
    
    def generate_dialogue(character_context, story_context)
    def generate_event(plot_needs, character_states)
    def generate_narrative(events, style_requirements)
```

## Key Metrics (Real Ones)

### Quality Metrics
1. **Coherence Score**: How well generated content maintains story consistency
2. **Character Consistency**: How well dialogue matches character personality
3. **Emotional Accuracy**: How well content reflects emotional states
4. **Plot Progression**: How effectively the story advances

### Diversity Metrics
1. **Semantic Diversity**: Measured by embedding similarity (not n-grams)
2. **Creative Novelty**: Unique plot developments per generation
3. **Dialogue Authenticity**: Natural language variation

### Performance Metrics
1. **Generation Speed**: Time per dialogue/event
2. **Token Efficiency**: Tokens consumed per quality output
3. **Context Window Usage**: Effective use of LLM context

## Implementation Phases

### Phase 1: LLM Integration (Current)
- [x] Environment variables configured
- [ ] LLM client implementation
- [ ] Basic prompt engineering
- [ ] Simple generation tests

### Phase 2: Character-Driven Generation
- [ ] Character personality ‚Üí prompt mapping
- [ ] Emotional state modeling
- [ ] Relationship-aware dialogue

### Phase 3: Story Coherence
- [ ] Context management system
- [ ] Plot tracking
- [ ] Event causality chains

### Phase 4: Quality Enhancement
- [ ] Multi-pass generation
- [ ] Self-critique loops
- [ ] Style consistency

## üî• CRITICAL ISSUES BEING FIXED

### Phase 1 Tasks (IN PROGRESS)
- [ ] **Archive Template Systems**: Move fake generators to legacy/
- [ ] **Complete LLM Client**: Test Gemini integration with real generation
- [ ] **New Architecture**: Create core/, models/, generators/ structure
- [ ] **Remove Fake Metrics**: Delete n-gram repetition detection

### Phase 2 Tasks (NEXT)
- [ ] **AI Character System**: Dynamic personality ‚Üí dialogue mapping
- [ ] **Story Context**: Maintain coherence across generations
- [ ] **Real Event Generation**: LLM-created events, not template selection

### Phase 3 Tasks (FOLLOWING)
- [ ] **Authentic Quality Metrics**: Semantic coherence, creativity scores
- [ ] **Enhancement Pipeline**: Multi-pass generation with improvement
- [ ] **Production Ready**: Cost optimization, error handling

## Success Criteria

### MVP (2 Weeks)
- [ ] 10 unique character dialogues (zero templates)
- [ ] Personality traits affect dialogue style measurably
- [ ] Story context maintained across 5+ events
- [ ] LLM costs <$5 for MVP test

### V1.0 (4 Weeks) 
- [ ] Complete 5000-word coherent story
- [ ] 3 distinguishable character voices
- [ ] Reader satisfaction ‚â•7/10
- [ ] Creative novelty score ‚â•0.8

## üéØ SuperClaude Commands to Execute

### Recommended Slash Commands:
```bash
/cleanup @ai_testing --focus 'template_systems,fake_metrics' --move-to legacy/
/implement @ai_testing/core/llm_client.py --integrate gemini-api --test-generation
/architect @ai_testing --new-structure 'core,models,generators,quality'
/test --llm-integration --validate 'real_generation,no_templates'
```

### Manual Tasks This Week:
1. **Complete REFACTOR_PLAN.md** ‚úÖ
2. **Update Project Documentation** ‚úÖ  
3. **Execute cleanup slash commands**
4. **Test LLM integration**
5. **Validate MVP criteria**

## Development Environment

### API Keys (Configured)
- `GEMINI_API_KEY` - Primary for development
- `OPENAI_API_KEY` - Backup option
- `ANTHROPIC_API_KEY` - Alternative option

### Test Configuration
```python
DEFAULT_MODEL = "gemini-2.0-flash"
MAX_TOKENS = 2000
TEMPERATURE = 0.7  # Balance creativity/coherence
```

## Code Quality Standards

### DO
- ‚úÖ Generate content dynamically via LLM
- ‚úÖ Use character state for prompt construction
- ‚úÖ Maintain context across generations
- ‚úÖ Validate output quality

### DON'T
- ‚ùå Use predefined content lists
- ‚ùå Random.choice() for dialogue
- ‚ùå Hardcode story events
- ‚ùå Fake metrics with template counting

---

**Project Status**: Transitioning from template system to genuine AI generation
**Priority**: Establish working LLM pipeline before adding features
**Deadline**: MVP by end of current sprint