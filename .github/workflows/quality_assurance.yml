name: Quality Assurance Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  # ✅ Removed daily schedule to reduce email notifications
  # Only runs on push/PR events now
  workflow_dispatch:
    # Allow manual trigger

permissions:
  contents: read

env:
  PYTHON_VERSION: '3.12'
  COVERAGE_THRESHOLD: 90
  PYTHONPATH: ${{ github.workspace }}/src:${{ github.workspace }}

jobs:
  code-quality:
    name: Code Quality Checks
    runs-on: ubuntu-22.04
    timeout-minutes: 15
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        cache-dependency-path: requirements.txt
        
    - name: Install dependencies
      shell: bash
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-asyncio pytest-cov coverage black isort flake8 mypy bandit safety
        
    - name: Code formatting check (Black)
      shell: bash
      run: |
        python -m black --check --diff src tests
      continue-on-error: true
        
    - name: Import sorting check (isort)
      shell: bash
      run: |
        python -m isort --check-only --diff src tests
      continue-on-error: true
        
    - name: Code style check (Flake8)
      shell: bash
      run: |
        python -m flake8 src tests --max-line-length=88 --extend-ignore=E203,W503,E501,W605,F401
      continue-on-error: true
        
    - name: Type checking (MyPy)
      shell: bash
      run: |
        python -m mypy src --ignore-missing-imports
      continue-on-error: true  # Optional for now

  security-scan:
    name: Security Scanning
    runs-on: ubuntu-22.04
    timeout-minutes: 10
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        cache-dependency-path: requirements.txt
        
    - name: Install security tools
      shell: bash
      run: |
        python -m pip install --upgrade pip
        pip install bandit safety
        
    - name: Security linting (Bandit)
      shell: bash
      run: |
        python -m bandit -r src -f json -o bandit-report.json || true
        python -m bandit -r src || echo "Bandit found issues but continuing"
      continue-on-error: true
        
    - name: Dependency vulnerability check (Safety)
      shell: bash
      run: |
        pip install -r requirements.txt
        python -m safety check --output json > safety-report.json || echo "Safety check created report"
        python -m safety check || echo "Safety found vulnerabilities but continuing"
      continue-on-error: true
        
    - name: Upload security reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json

  test-suite:
    name: Test Suite
    runs-on: ubuntu-22.04
    timeout-minutes: 30
    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11', '3.12']
      fail-fast: false
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'
        cache-dependency-path: requirements.txt
        
    - name: Install dependencies
      shell: bash
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-test.txt
        pip install coverage httpx pytest-timeout
        
    - name: Run tests with coverage
      shell: bash
      run: |
        python -m pytest \
          -m "not requires_services" \
          --ignore=tests/test_ai_intelligence_integration.py \
          --ignore=tests/test_api_endpoints_comprehensive.py \
          --ignore=tests/test_api_intelligence_integration.py \
          --ignore=tests/test_character_system_comprehensive.py \
          --ignore=tests/test_director_agent.py \
          --ignore=tests/test_enhanced_bridge.py \
          --ignore=tests/test_event_integration.py \
          --ignore=tests/test_integration_comprehensive.py \
          --ignore=tests/test_llm_integration.py \
          --ignore=tests/test_persona_agent.py \
          --ignore=tests/test_story_generation_comprehensive.py \
          --ignore=tests/integration \
          --cov=src \
          --cov-report=xml \
          --cov-report=html \
          --cov-report=term-missing \
          --cov-fail-under=60 \
          --junitxml=test-results.xml \
          -v \
          --tb=short \
          --durations=10 \
          || echo "Some tests failed but continuing"
      continue-on-error: true
          
    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-${{ matrix.python-version }}
        path: |
          test-results.xml
          htmlcov/
          coverage.xml
          
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v4
      if: matrix.python-version == env.PYTHON_VERSION
      with:
        file: coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-22.04
    timeout-minutes: 20
    needs: [code-quality, test-suite]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        cache-dependency-path: requirements.txt
        
    - name: Install dependencies
      shell: bash
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-test.txt
        pip install coverage httpx pytest-timeout
        
    - name: Run integration tests
      shell: bash
      run: |
        python -m pytest tests/ \
          -m "integration" \
          --ignore=tests/test_ai_intelligence_integration.py \
          --ignore=tests/test_api_endpoints_comprehensive.py \
          --ignore=tests/test_api_intelligence_integration.py \
          --ignore=tests/test_character_system_comprehensive.py \
          --ignore=tests/test_director_agent.py \
          --ignore=tests/test_enhanced_bridge.py \
          --ignore=tests/test_event_integration.py \
          --ignore=tests/test_integration_comprehensive.py \
          --ignore=tests/test_llm_integration.py \
          --ignore=tests/test_persona_agent.py \
          --ignore=tests/test_story_generation_comprehensive.py \
          --tb=short \
          -v \
          --maxfail=5 \
          --timeout=300 \
          || echo "Integration tests completed with some failures"
      continue-on-error: true
          
    - name: Run API tests
      shell: bash
      run: |
        python -m pytest tests/ \
          -m "api" \
          --ignore=tests/test_ai_intelligence_integration.py \
          --ignore=tests/test_api_endpoints_comprehensive.py \
          --ignore=tests/test_api_intelligence_integration.py \
          --ignore=tests/test_character_system_comprehensive.py \
          --ignore=tests/test_director_agent.py \
          --ignore=tests/test_enhanced_bridge.py \
          --ignore=tests/test_event_integration.py \
          --ignore=tests/test_integration_comprehensive.py \
          --ignore=tests/test_llm_integration.py \
          --ignore=tests/test_persona_agent.py \
          --ignore=tests/test_story_generation_comprehensive.py \
          --tb=short \
          -v \
          --maxfail=5 \
          --timeout=300 \
          || echo "API tests completed with some failures"
      continue-on-error: true

  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-22.04
    timeout-minutes: 15
    needs: [test-suite]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        cache-dependency-path: requirements.txt
        
    - name: Install dependencies
      shell: bash
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-test.txt
        pip install coverage httpx pytest-timeout pytest-benchmark
        
    - name: Run performance tests
      shell: bash
      run: |
        python -m pytest tests/ \
          -m "performance" \
          --tb=short \
          -v \
          --benchmark-only \
          --benchmark-json=benchmark.json
      continue-on-error: true
        
    - name: Upload performance results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: performance-results
        path: benchmark.json

  quality-gates:
    name: Quality Gates
    runs-on: ubuntu-22.04
    timeout-minutes: 20
    needs: [code-quality, security-scan, test-suite]
    continue-on-error: true
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        cache-dependency-path: requirements.txt
        
    - name: Install dependencies
      shell: bash
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-asyncio pytest-cov coverage black isort flake8 mypy bandit safety
        
    - name: Run quality gates
      shell: bash
      run: |
        python scripts/quality_gates.py --report quality_report.json
        
    - name: Upload quality report
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: quality-report
        path: quality_report.json
        
    - name: Comment quality results on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const path = 'quality_report.json';
          
          if (fs.existsSync(path)) {
            const report = JSON.parse(fs.readFileSync(path, 'utf8'));
            const status = report.overall_passed ? '✅ PASSED' : '❌ FAILED';
            const summary = report.summary;
            
            const comment = `## Quality Gates Report ${status}
            
            **Summary:**
            - Total Gates: ${summary.total}
            - Passed: ${summary.passed}
            - Failed: ${summary.failed}
            - Required Failed: ${summary.required_failed}
            
            **Gate Results:**
            ${Object.entries(report.gates).map(([name, gate]) => 
              `- ${gate.passed ? '✅' : '❌'} ${name}${gate.required ? '' : ' (Optional)'}`
            ).join('\n')}
            
            ${report.overall_passed ? '' : '**Action Required:** Fix failing quality gates before merge.'}
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
          }

  build-and-package:
    name: Build and Package
    runs-on: ubuntu-22.04
    timeout-minutes: 10
    needs: [quality-gates]
    continue-on-error: true
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        cache-dependency-path: requirements.txt
        
    - name: Install build dependencies
      shell: bash
      run: |
        python -m pip install --upgrade pip
        pip install build twine
        
    - name: Build package
      shell: bash
      run: |
        python -m build
        
    - name: Check package
      shell: bash
      run: |
        python -m twine check dist/*
        
    - name: Upload build artifacts
      uses: actions/upload-artifact@v4
      with:
        name: build-artifacts
        path: dist/

  documentation:
    name: Documentation
    runs-on: ubuntu-22.04
    timeout-minutes: 10
    needs: [code-quality]
    continue-on-error: true
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        cache-dependency-path: requirements.txt
        
    - name: Install documentation dependencies
      shell: bash
      run: |
        python -m pip install --upgrade pip
        pip install mkdocs mkdocs-material mkdocstrings[python]
        
    - name: Build documentation
      shell: bash
      run: |
        mkdocs build
      continue-on-error: true
        
    - name: Upload documentation
      uses: actions/upload-artifact@v4
      with:
        name: documentation
        path: site/
        
    - name: Deploy documentation to GitHub Pages
      if: github.event_name == 'push' && github.ref == 'refs/heads/main'
      uses: peaceiris/actions-gh-pages@v4
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        publish_dir: ./site

  summary:
    name: Quality Assurance Summary
    runs-on: ubuntu-22.04
    if: always()
    needs: [
      code-quality,
      security-scan, 
      test-suite
    ]
    
    steps:
    - name: Check overall status
      shell: bash
      run: |
        echo "Quality Assurance Pipeline Summary:"
        echo "Code Quality: ${{ needs.code-quality.result }}"
        echo "Security Scan: ${{ needs.security-scan.result }}"
        echo "Test Suite: ${{ needs.test-suite.result }}"
        
        if [[ "${{ needs.code-quality.result }}" == "success" ]] && \
           [[ "${{ needs.security-scan.result }}" == "success" ]] && \
           [[ "${{ needs.test-suite.result }}" == "success" ]]; then
          echo "✅ Core quality gates passed"
        else
          echo "⚠️ Some quality checks had issues (allowed to continue)"
        fi
