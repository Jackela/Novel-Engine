# Ralph Progress Log
Started: Fri Feb  6 10:46:57 CST 2026
---

## Codebase Patterns
- When modifying KnowledgeIngestionService, remember it now uses IngestionProcessorFactory for content-type-specific chunking and metadata enrichment
- New processors can be added by implementing IIngestionProcessor and registering in IngestionProcessorFactory
- All tests in tests/unit/contexts/knowledge/application/services/test_knowledge_ingestion_service.py must pass after changes
- Use `src.contexts.*` absolute imports in adapter files (not relative imports like `....application`)
- Infrastructure adapters in `src/contexts/knowledge/infrastructure/adapters/` should export from `__init__.py`
- Application services in `src/contexts/knowledge/application/services/` should export from `__init__.py`

## 2026-02-06 - OPT-001
- What was implemented:
  - Created IIngestionProcessor interface in application/ports
  - Implemented 7 processors: GenericProcessor, LoreProcessor, CharacterProcessor, SceneProcessor, PlotlineProcessor, ItemProcessor, LocationProcessor
  - Created IngestionProcessorFactory with SourceType -> processor mapping and GenericProcessor fallback
  - Refactored KnowledgeIngestionService to use processor factory for chunking strategy and metadata enrichment
  - Added 40 new unit tests for processor abstraction in test_ingestion_processors.py
- Files changed:
  - src/contexts/knowledge/application/ports/i_ingestion_processor.py (new)
  - src/contexts/knowledge/application/services/ingestion_processors.py (new)
  - src/contexts/knowledge/application/services/ingestion_processor_factory.py (new)
  - src/contexts/knowledge/application/services/knowledge_ingestion_service.py (modified)
  - tests/unit/contexts/knowledge/application/services/test_ingestion_processors.py (new)
- **Learnings for future iterations:**
  - The KnowledgeIngestionService now accepts an optional processor_factory parameter for injection/testing
  - Each processor defines chunking defaults via get_chunking_strategy() and enriches metadata via enrich_metadata()
  - Processors do NOT handle embedding or vector storage - that remains in the service layer
  - All existing tests pass (64/64) confirming no regressions

## 2026-02-06 - OPT-002
- What was implemented:
  - Created EmbeddingCacheService with LRU eviction + TTL expiration (application layer)
  - Cache keys use sha256(text + model) for uniqueness per model
  - Created CachedEmbeddingService adapter implementing IEmbeddingService (infrastructure layer)
  - Made EmbeddingServiceAdapter internal cache pluggable via enable_internal_cache parameter
  - Added 45 unit tests: 29 for EmbeddingCacheService, 16 for CachedEmbeddingService
- Files changed:
  - src/contexts/knowledge/application/services/embedding_cache_service.py (new)
  - src/contexts/knowledge/infrastructure/adapters/cached_embedding_service.py (new)
  - src/contexts/knowledge/infrastructure/adapters/embedding_generator_adapter.py (modified - added enable_internal_cache)
  - src/contexts/knowledge/application/services/__init__.py (modified - exports)
  - src/contexts/knowledge/infrastructure/adapters/__init__.py (modified - exports)
  - tests/unit/contexts/knowledge/application/services/test_embedding_cache_service.py (new)
  - tests/unit/contexts/knowledge/infrastructure/adapters/test_cached_embedding_service.py (new)
- **Learnings for future iterations:**
  - CacheService interface designed for future Redis backing (get/put/put_batch/get_batch/invalidate)
  - CachedEmbeddingService uses decorator pattern - wraps delegate without modifying it
  - Structlog logging added for cache_hit/cache_miss events with model and key info
  - LRU eviction is manual via list tracking (OrderedDict not used due to need for index operations)
  - All cache tests are fast (no sleep except TTL test which waits 1.1s)
---
