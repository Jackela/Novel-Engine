# Ralph Progress Log - Warzone 4: AI Brain
Started: 2025-02-03

Campaign: WARZONE 4 - Building the RAG (Retrieval-Augmented Generation) engine
Branch: feat/code-citadel
Stories: 40 (BRAIN-001 through BRAIN-040)

---

## Codebase Patterns

### Architecture
- **Hexagonal Architecture**: Routers -> Services -> Domain. No business logic in routers.
- **Result Pattern**: Use `Result[T, E]` for error handling in services (see `src/core/result.py`)
- **Domain Events**: Use events for cross-context communication, not direct imports
- **Import Linting**: Rules defined in `.importlinter` to enforce architectural boundaries
- **Vector Storage**: ChromaDB adapter in `src/contexts/knowledge/infrastructure/adapters/chromadb_vector_store.py`

### Frontend
- **Zustand Stores**: Feature-based organization (4 stores: authStore, orchestrationStore, decisionStore, weaverStore)
- **State Management Hierarchy**: TanStack Query -> Zustand -> React Hook Form -> useState
- **Schema SSOT**: Backend Pydantic schemas (`src/api/schemas.py`) drive frontend Zod schemas (`frontend/src/types/schemas.ts`)

### Testing
- **TDD/BDD**: Write failing test first, implement minimum code, verify with E2E
- **Test File Organization**: Keep files under 500 lines, split by functionality
- **Quality Gates**: `pytest tests/ && npm run test:e2e && mypy . && npm run type-check`

### Schema Synchronization
- Backend schemas are SSOT in `src/api/schemas.py`
- Frontend schemas live in `frontend/src/types/schemas.ts` (Zod)
- Regenerate OpenAPI with `python scripts/generate_openapi.py` after schema changes
- Zod's `z.number()` is correct for both Python `int` and `float`

---

## Warzone 4: AI Brain - Campaign Overview

### Goal
Build a RAG (Retrieval-Augmented Generation) engine and Prompt Engineering Lab to give the AI system "long-term memory."

### Key Technologies
- **Vector Database**: ChromaDB for semantic search
- **Embeddings**: OpenAI `text-embedding-3-small` (1536 dimensions)
- **LLM Providers**: OpenAI, Anthropic Claude, Google Gemini, Ollama (local)
- **Knowledge Graph**: NetworkX/Neo4j for entity relationships

### Story Breakdown

#### Core Infrastructure (7 stories)
- BRAIN-001: ChromaDB setup ✅
- BRAIN-002: Embedding service
- BRAIN-003: Knowledge entry entity
- BRAIN-004: Knowledge ingestion service
- BRAIN-005: Auto-sync event listeners
- BRAIN-006: Context retrieval service (RAG)
- BRAIN-007: RAG-enhanced generation

#### RAG Enhancement (6 stories)
- BRAIN-008: Hybrid search (Vector + BM25)
- BRAIN-009: Query rewriting & expansion
- BRAIN-010: Re-ranking service
- BRAIN-011: Context window optimization
- BRAIN-012: Citation & source attribution
- BRAIN-013: Multi-hop reasoning

#### Prompt Engineering (9 stories)
- BRAIN-014: Prompt template entity
- BRAIN-015: Prompt management API
- BRAIN-016: Version control & history
- BRAIN-017: Template inheritance & composition
- BRAIN-018: A/B testing framework
- BRAIN-019: Prompt Engineering Lab UI
- BRAIN-020: Prompt playground
- BRAIN-021: Prompt comparison view
- BRAIN-022: Prompt analytics

#### LLM Integration (6 stories)
- BRAIN-023: Model registry
- BRAIN-024: Anthropic Claude integration
- BRAIN-025: Google Gemini integration
- BRAIN-026: OpenAI GPT-4 Turbo integration
- BRAIN-027: Local LLM support (Ollama)
- BRAIN-028: Model routing strategy

#### Knowledge Graph (4 stories)
- BRAIN-029: Entity extraction service
- BRAIN-030: Relationship extraction
- BRAIN-031: Graph storage (NetworkX/Neo4j)
- BRAIN-032: Graph-based context retrieval

#### Settings & Monitoring (3 stories)
- BRAIN-033: Brain settings UI
- BRAIN-034: Token usage tracker
- BRAIN-035: Cost dashboard

#### Features (5 stories)
- BRAIN-036: Context inspector
- BRAIN-037: Chat with Story
- BRAIN-038: Smart tagging service
- BRAIN-039: Automatic chunking strategy
- BRAIN-040: E2E Brain Test

---

## [2025-02-03] - BRAIN-001 ✅
- Implemented ChromaDB vector store adapter with full CRUD operations
- Created IVectorStore port interface with upsert, query, delete, clear, health_check, count methods
- Added ChromaDB health check endpoint at GET /health/chromadb
- Added register_chromadb_check method to HealthMonitor for system-wide monitoring
- All 23 unit tests passing, including data persistence across restarts test
- Files changed:
  - `pyproject.toml`: Added chromadb>=0.5.0 and tiktoken>=0.7.0 dependencies
  - `src/contexts/knowledge/application/ports/i_vector_store.py`: IVectorStore port, VectorDocument, QueryResult, UpsertResult value objects
  - `src/contexts/knowledge/infrastructure/adapters/chromadb_vector_store.py`: ChromaDBVectorStore adapter
  - `src/api/health_system.py`: Added register_chromadb_check method
  - `src/api/routers/health.py`: Added /health/chromadb endpoint
  - `tests/unit/contexts/knowledge/infrastructure/adapters/test_chromadb_vector_store.py`: Full test coverage

**Learnings for future iterations:**
- ChromaDB uses PersistentClient for embedded mode - no separate server needed
- Default storage is `.data/chroma/` - configurable via CHROMA_PERSIST_DIR env var
- Collection cache must be instance-level (not class-level) to avoid cross-test pollution
- Cosine similarity is the default distance metric for text embeddings
- ChromaDB's `query` returns distances that need to be converted to similarity scores (1 - distance)

---

## Next Story for Ralph
- **BRAIN-002**: Infra: Embedding Service Adapter
- Priority: 2
- Focus: Create EmbeddingService adapter wrapping OpenAI text-embedding-3-small

---
