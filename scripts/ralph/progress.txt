# Ralph Progress Log - Warzone 4: AI Brain
Started: 2025-02-05 (Reset)

Campaign: WARZONE 4 - Building the RAG (Retrieval-Augmented Generation) engine
Branch: feat/code-citadel

---

## Codebase Patterns

### Architecture
- **Hexagonal Architecture**: Routers -> Services -> Domain. No business logic in routers.
- **Result Pattern**: Use `Result[T, E]` for error handling in services (see `src/core/result.py`)
- **Domain Events**: Use events for cross-context communication, not direct imports
- **Import Linting**: Rules defined in `.importlinter` to enforce architectural boundaries
- **Vector Storage**: ChromaDB adapter in `src/contexts/knowledge/infrastructure/adapters/chromadb_vector_store.py`
- **Type Annotations**: Use `from __future__ import annotations` and import List/Tuple from typing for complex types
- **RAG Retrieval**: RetrievalService in `src/contexts/knowledge/application/services/retrieval_service.py` with filtering and deduplication
- **BM25 Keyword Search**: BM25Retriever in `src/contexts/knowledge/application/services/bm25_retriever.py` for exact keyword matching
- **Hybrid Retrieval**: HybridRetriever in `src/contexts/knowledge/application/services/hybrid_retriever.py` combines vector and BM25 with RRF
- **Query Rewriting**: QueryRewriter in `src/contexts/knowledge/application/services/query_rewriter.py` with SYNONYM/DECOMPOSE/CLARIFICATION strategies
- **Reranking**: IReranker port in `src/contexts/knowledge/application/ports/i_reranker.py` and RerankService with fallback behavior
- **Token Counting**: TokenCounter in `src/contexts/knowledge/application/services/token_counter.py` with multi-provider tiktoken support
- **Context Optimization**: ContextOptimizer in `src/contexts/knowledge/application/services/context_optimizer.py` with 4 packing strategies (relevance, diversity, remove_redundancy, compress_summaries)
- **Prompt Templates**: PromptTemplate entity in `src/contexts/knowledge/domain/models/prompt_template.py` with {{variable}} syntax and version tracking
- **Prompt Inheritance**: Use `extends` field and `{{> template}}` syntax for template composition. Variable override works by child having same-named variable.
- **Prompt Repository**: IPromptRepository port in `src/contexts/knowledge/application/ports/i_prompt_repository.py` with CRUD, version history, and search
- **Model Registry**: ModelRegistry in `src/contexts/knowledge/application/services/model_registry.py` with task-based routing and aliases
- **Entity Extraction**: EntityExtractionService in `src/contexts/knowledge/application/services/entity_extraction_service.py` with LLM-based extraction
- **Co-reference Resolution**: CoreferenceResolutionService in `src/contexts/knowledge/application/services/coreference_resolution_service.py` with heuristic + LLM fallback
- **Large Text Processing**: extract_large_text() with chunking (chunk_size, overlap) and merging for texts exceeding token limits
- **Token Tracking**: TokenTracker in `src/contexts/knowledge/application/services/token_tracker.py` with decorator/context manager support
- **Token Usage Entity**: TokenUsage in `src/contexts/knowledge/domain/models/token_usage.py` with cost calculation using model pricing
- **Token Usage Repository**: ITokenUsageRepository port in `src/contexts/knowledge/application/ports/i_token_usage_repository.py` with InMemoryTokenUsageRepository implementation
- **Budget Alerts**: BudgetAlertService in `src/contexts/knowledge/application/services/budget_alert_service.py` with threshold-based alerting
- **Alert Configuration**: BudgetAlertConfig in `src/contexts/knowledge/domain/models/budget_alert.py` with threshold types, operators, severity, frequency
- **Real-time Broadcasting**: RealtimeUsageBroadcaster in `src/api/routers/brain_settings.py` provides SSE-based live token updates to frontend clients
- **Hexagonal Architecture**: Routers -> Services -> Domain. No business logic in routers.
- **Result Pattern**: Use `Result[T, E]` for error handling in services (see `src/core/result.py`)
- **Domain Events**: Use events for cross-context communication, not direct imports
- **Import Linting**: Rules defined in `.importlinter` to enforce architectural boundaries
- **Vector Storage**: ChromaDB adapter in `src/contexts/knowledge/infrastructure/adapters/chromadb_vector_store.py`
- **Type Annotations**: Use `from __future__ import annotations` and import List/Tuple from typing for complex types
- **RAG Retrieval**: RetrievalService in `src/contexts/knowledge/application/services/retrieval_service.py` with filtering and deduplication
- **BM25 Keyword Search**: BM25Retriever in `src/contexts/knowledge/application/services/bm25_retriever.py` for exact keyword matching
- **Hybrid Retrieval**: HybridRetriever in `src/contexts/knowledge/application/services/hybrid_retriever.py` combines vector and BM25 with RRF
- **Query Rewriting**: QueryRewriter in `src/contexts/knowledge/application/services/query_rewriter.py` with SYNONYM/DECOMPOSE/CLARIFICATION strategies
- **Reranking**: IReranker port in `src/contexts/knowledge/application/ports/i_reranker.py` and RerankService with fallback behavior
- **Token Counting**: TokenCounter in `src/contexts/knowledge/application/services/token_counter.py` with multi-provider tiktoken support
- **Context Optimization**: ContextOptimizer in `src/contexts/knowledge/application/services/context_optimizer.py` with 4 packing strategies (relevance, diversity, remove_redundancy, compress_summaries)
- **Prompt Templates**: PromptTemplate entity in `src/contexts/knowledge/domain/models/prompt_template.py` with {{variable}} syntax and version tracking
- **Prompt Inheritance**: Use `extends` field and `{{> template}}` syntax for template composition. Variable override works by child having same-named variable.
- **Prompt Repository**: IPromptRepository port in `src/contexts/knowledge/application/ports/i_prompt_repository.py` with CRUD, version history, and search
- **Model Registry**: ModelRegistry in `src/contexts/knowledge/application/services/model_registry.py` with task-based routing and aliases
- **Entity Extraction**: EntityExtractionService in `src/contexts/knowledge/application/services/entity_extraction_service.py` with LLM-based extraction
- **Co-reference Resolution**: CoreferenceResolutionService in `src/contexts/knowledge/application/services/coreference_resolution_service.py` with heuristic + LLM fallback
- **Large Text Processing**: extract_large_text() with chunking (chunk_size, overlap) and merging for texts exceeding token limits
- **Token Tracking**: TokenTracker in `src/contexts/knowledge/application/services/token_tracker.py` with decorator/context manager support
- **Token Usage Entity**: TokenUsage in `src/contexts/knowledge/domain/models/token_usage.py` with cost calculation using model pricing
- **Token Usage Repository**: ITokenUsageRepository port in `src/contexts/knowledge/application/ports/i_token_usage_repository.py` with InMemoryTokenUsageRepository implementation
- **Budget Alerts**: BudgetAlertService in `src/contexts/knowledge/application/services/budget_alert_service.py` with threshold-based alerting
- **Alert Configuration**: BudgetAlertConfig in `src/contexts/knowledge/domain/models/budget_alert.py` with threshold types, operators, severity, frequency

### Frontend
- **Zustand Stores**: Feature-based organization (4 stores: authStore, orchestrationStore, decisionStore, weaverStore)
- **State Management Hierarchy**: TanStack Query -> Zustand -> React Hook Form -> useState
- **Schema SSOT**: Backend Pydantic schemas (`src/api/schemas.py`) drive frontend Zod schemas (`frontend/src/types/schemas.ts`)

### Testing
- **TDD/BDD**: Write failing test first, implement minimum code, verify with E2E
- **Test File Organization**: Keep files under 500 lines, split by functionality
- **Quality Gates**: `pytest tests/ && npm run test:e2e && mypy . && npm run type-check`

### Schema Synchronization
- Backend schemas are SSOT in `src/api/schemas.py`
- Frontend schemas live in `frontend/src/types/schemas.ts` (Zod)
- Regenerate OpenAPI with `python scripts/generate_openapi.py` after schema changes
- Zod's `z.number()` is correct for both Python `int` and `float`

---

## 2025-02-05 - BRAIN-035B-01
- **What was implemented:**
  - Added GET `/api/brain/models` endpoint returning model pricing data from ModelRegistry
  - Added `ModelPricingResponse` Pydantic model with provider, model name, display name, costs, and context info
  - Added frontend `getModelPricing()` API function
  - Created model comparison table in Usage tab of Brain Settings page
  - Table displays models grouped by provider (OpenAI, Anthropic, Gemini, Ollama)
  - Shows cost per 1M tokens (input/output) and context window size
- **Files changed:**
  - `src/api/routers/brain_settings.py` - Added model pricing endpoint
  - `frontend/src/features/routing/api/brainSettingsApi.ts` - Added API function
  - `frontend/src/features/routing/components/BrainSettingsPage.tsx` - Added comparison table UI
- **Learnings for future iterations:**
  - ModelRegistry DEFAULT_MODELS dict contains all model definitions with pricing
  - Use `provider` value for API responses, format for display in UI
  - Brain Settings Usage tab is the right place for pricing comparison
  - Table component from shadcn/ui provides consistent styling

---

## 2025-02-05 - BRAIN-035B-02
- **What was implemented:**
  - Added preset/custom mode toggle for date range filtering in Usage tab
  - Preset mode: 7, 30, 90 day quick-select buttons (existing functionality enhanced)
  - Custom mode: Native HTML date inputs for start/end date selection
  - Apply button calculates days from custom date range
  - Filter applies to all Usage tab charts (Tokens Over Time, Cost by Model, Provider Distribution)
  - Defaults to 30 days in preset mode
- **Files changed:**
  - `frontend/src/features/routing/components/BrainSettingsPage.tsx` - Added date range picker UI
- **Learnings for future iterations:**
  - Use `effectiveDays` pattern to calculate days from both preset and custom date ranges
  - Native HTML date inputs work well and don't require additional dependencies
  - Mode toggle (preset vs custom) provides good UX flexibility

---

## 2025-02-05 - BRAIN-035B-03
- **What was implemented:**
  - Added GET `/api/brain/usage/export` endpoint returning CSV file with usage data
  - CSV columns: Timestamp, Provider, Model, Input/Output/Total Tokens, Costs, Latency, Success
  - Added `exportUsageCsv()` frontend API function with file download handling
  - Added Export CSV button with Download icon to Usage tab header
  - Export respects current date range filter (uses `effectiveDays`)
- **Files changed:**
  - `src/api/routers/brain_settings.py` - Added CSV export endpoint
  - `frontend/src/features/routing/api/brainSettingsApi.ts` - Added export function
  - `frontend/src/features/routing/components/BrainSettingsPage.tsx` - Added export button
- **Learnings for future iterations:**
  - Use FastAPI Response with media_type "text/csv" for CSV downloads
  - Set Content-Disposition header with filename for proper browser download behavior
  - Frontend: Use blob download pattern with createObjectURL for file downloads

---

## 2025-02-05 - BRAIN-035B-04
- **What was implemented:**
  - Added RealtimeUsageBroadcaster class for SSE-based real-time token usage broadcasting
  - Added GET `/api/brain/usage/stream` SSE endpoint for live token updates
  - Added frontend types for real-time usage events (session_start, token_update, session_complete, session_state, error)
  - Added `useRealtimeUsage` React hook for subscribing to SSE events
  - Added RealtimeUsageCounter component that displays live token usage during generation
  - Counter shows active sessions with tokens, cost, model info, and connection status
  - Auto-removes completed sessions after 5 seconds from UI
- **Files changed:**
  - `src/api/routers/brain_settings.py` - Added RealtimeUsageBroadcaster and SSE endpoint
  - `frontend/src/features/routing/api/brainSettingsApi.ts` - Added event types and streamRealtimeUsage function
  - `frontend/src/features/routing/components/BrainSettingsPage.tsx` - Added useRealtimeUsage hook and RealtimeUsageCounter component
- **Learnings for future iterations:**
  - SSE pattern: Use `yield f"data: {json}\n\n"` format for Server-Sent Events
  - Frontend: EventSource auto-reconnects on disconnect - handle cleanup in useEffect return
  - Global broadcaster pattern allows fan-out to multiple connected clients
  - Session-based tracking isolates concurrent user generations
  - Real-time counter appears at top of Usage tab when active sessions exist

---

## 2025-02-05 - BRAIN-034A
- **What was implemented:**
  - Added ITokenUsageRepository port with filtering, aggregation, and persistence methods
  - Added InMemoryTokenUsageRepository adapter for development/testing
  - Added TokenTracker service with decorator and context manager support
  - Added input_tokens, output_tokens, raw_usage fields to LLMResponse
  - Updated Claude, Gemini, Ollama, and OpenAI LLM clients to populate new token fields
  - Added comprehensive unit tests for TokenTracker
- **Files changed:**
  - `src/contexts/knowledge/application/ports/i_llm_client.py` - Added input_tokens, output_tokens, raw_usage to LLMResponse
  - `src/contexts/knowledge/application/ports/i_token_usage_repository.py` - New port for token usage persistence
  - `src/contexts/knowledge/application/services/token_tracker.py` - New service with decorator/context manager
  - `src/contexts/knowledge/infrastructure/adapters/__init__.py` - Exported new repository
  - `src/contexts/knowledge/infrastructure/adapters/in_memory_token_usage_repository.py` - New adapter
  - `src/contexts/knowledge/infrastructure/adapters/claude_llm_client.py` - Populate token fields
  - `src/contexts/knowledge/infrastructure/adapters/gemini_llm_client.py` - Populate token fields
  - `src/contexts/knowledge/infrastructure/adapters/ollama_llm_client.py` - Populate token fields
  - `src/contexts/knowledge/infrastructure/adapters/openai_llm_client.py` - Populate token fields
  - `tests/unit/contexts/knowledge/application/services/test_token_tracker.py` - New test file
- **Learnings for future iterations:**
  - Use regular class instead of dataclass when defining custom __init__ with keyword-only arguments
  - Move runtime type imports (like LLMResponse) out of TYPE_CHECKING block if used for isinstance checks
  - TokenTracker decorator tracks LLM calls automatically via @tracker.track_llm_call(model_ref="...")
  - Context manager pattern: async with tracker.track_call(model, prompt=...) as ctx: ctx.record_success(...)
  - All 16 tests pass for TokenTracker functionality

---

## 2025-02-05 - BRAIN-036-01
- **What was implemented:**
  - Added View AI Context button to scene editor toolbar
  - Added ragEnabled and onViewAIContext props to EditorComponent
  - Button uses Brain icon from lucide-react
  - Button only visible when RAG is enabled (ragEnabled prop)
  - Button is disabled during streaming generation
  - Follows existing shadcn/ui Button patterns with outline variant
- **Files changed:**
  - `frontend/src/components/narrative/EditorComponent.tsx` - Added View AI Context button
- **Learnings for future iterations:**
  - EditorToolbar is nested function inside EditorComponent (lines 84-184)
  - Brain icon from lucide-react fits the AI theme
  - Use spread operator with conditional check for optional props: `{...(prop !== undefined && { prop })}`
  - EditorComponent receives sceneId, prompt, context props from parent
  - Parent component needs to pass ragEnabled from brainSettings.rag_config.enabled

---

## 2025-02-05 - BRAIN-036-02
- **What was implemented:**
  - Created ContextInspector sliding panel component using shadcn/ui Sheet
  - Added GET `/api/brain/context` endpoint returning retrieved RAG chunks with metadata
  - Added RetrievedChunkResponse and RAGContextResponse schemas
  - Panel shows retrieved chunks with source info (type, ID, content)
  - Displays relevance scores with color coding (green >= 0.8, yellow >= 0.6, orange < 0.6)
  - Shows token count per chunk
  - Integrated with NarrativeEditorLayout with state management
  - Uses scene content as query for context retrieval
- **Files changed:**
  - `src/api/schemas.py` - Added RAGContextResponse, RetrievedChunkResponse
  - `src/api/routers/brain_settings.py` - Added get_rag_context endpoint
  - `frontend/src/features/routing/api/brainSettingsApi.ts` - Added getRAGContext API function and types
  - `frontend/src/components/narrative/ContextInspector.tsx` - New component
  - `frontend/src/components/narrative/NarrativeEditorLayout.tsx` - Integrated ContextInspector
- **Learnings for future iterations:**
  - TokenCounter.count(text) returns TokenCountResult, access token_count via result.token_count
  - Sheet component from shadcn/ui provides sliding panel behavior (side="right" default)
  - Use exactOptionalPropertyTypes: true requires handling undefined props carefully with spread operator
  - RetrievalService.get_sources() returns list of source dicts with source_type, source_id, display_name, etc.
  - Source type badges use color mapping for visual distinction (CHARACTER=purple, LORE=blue, etc.)

---

## 2025-02-05 - BRAIN-036-03
- **What was implemented:**
  - Added `used` boolean field to RetrievedChunkResponse Pydantic model
  - Added `used_threshold` query parameter to GET `/api/brain/context` endpoint (default: 0.7)
  - Chunks with score >= used_threshold are marked as "used" in the response
  - Updated frontend RetrievedChunkResponse TypeScript interface with `used` field
  - Added visual highlighting for used chunks in ContextInspector:
    - Green border and background tint (bg-green-50/50, border-green-200)
    - "Used" badge with CheckCircle2 icon
    - Dark mode support (bg-green-950/30, border-green-800)
- **Files changed:**
  - `src/api/schemas.py` - Added `used` field to RetrievedChunkResponse
  - `src/api/routers/brain_settings.py` - Added used_threshold parameter and logic
  - `frontend/src/features/routing/api/brainSettingsApi.ts` - Added `used` field to interface
  - `frontend/src/components/narrative/ContextInspector.tsx` - Added visual highlighting
- **Learnings for future iterations:**
  - Used chunks are determined by relevance threshold (0.7 by default)
  - Visual distinction uses conditional classes based on `chunk.used` boolean
  - CheckCircle2 icon from lucide-react for used indicator badge
  - Green color scheme indicates "used" state (consistent with success/positive semantics)

---

## 2025-02-05 - BRAIN-036-04
- **What was implemented:**
  - Added Checkbox component from shadcn/ui for chunk selection
  - Added checkboxes to each chunk card in ContextInspector
  - Added Select All / Deselect All buttons in header
  - Added Regenerate button in footer that appears when chunks are selected
  - Added visual ring styling (ring-2 ring-primary) for selected chunks
  - Added selection count indicator in header description
  - Added optional onRegenerateWithChunks callback prop for future integration
  - Chunks are deselected when fetching new context
- **Files changed:**
  - `frontend/src/components/ui/checkbox.tsx` - New component from shadcn/ui
  - `frontend/src/components/narrative/ContextInspector.tsx` - Added checkboxes, selection state, regenerate button
  - `frontend/src/components/narrative/NarrativeEditorLayout.tsx` - Added onRegenerateWithChunks prop
- **Learnings for future iterations:**
  - Use @radix-ui/react-checkbox for accessible checkbox implementation
  - Set<string> is efficient for tracking selected IDs with O(1) lookup
  - Ring styling (ring-2 ring-primary ring-offset-2) provides clear visual feedback for selection
  - Toast notifications provide feedback for regenerate action
  - The actual scene generation integration with selected chunks is a future enhancement

---

## 2025-02-05 - BRAIN-036-05
- **What was implemented:**
  - Added Progress component from shadcn/ui for context window display
  - Added context window usage display between header and content
  - Shows used tokens / limit with percentage
  - Progress bar with color coding (default, orange at 80%, red at 95%)
  - Warning message with AlertTriangle icon when approaching limit (80%+)
  - Different warning messages for near limit vs nearly full
  - Added contextTokenLimit prop (defaults to 4000)
- **Files changed:**
  - `frontend/src/components/ui/progress.tsx` - New component from shadcn/ui
  - `frontend/src/components/narrative/ContextInspector.tsx` - Added context window display
- **Learnings for future iterations:**
  - Use @radix-ui/react-progress for accessible progress bar
  - Threshold-based color coding helps users understand urgency
  - The default context token limit of 4000 is typical for many LLMs
  - Using Tailwind's `[&>div]:bg-*` syntax allows targeting ProgressPrimitive.Indicator

---

## 2025-02-05 - BRAIN-037A-01
- **What was implemented:**
  - Added POST /api/brain/chat endpoint
  - Created ChatMessage, ChatRequest, ChatChunk Pydantic models
  - Endpoint accepts query parameter and optional chat_history
  - Returns SSE (Server-Sent Events) streaming response
  - Integrates with RAG when enabled (RetrievalService for context)
  - Mock streaming response with word-by-word chunks for now
  - Full LLM integration will be in future story (BRAIN-037A-02)
- **Files changed:**
  - `src/api/routers/brain_settings.py` - Added chat endpoint and models
- **Learnings for future iterations:**
  - Use AsyncIterator for SSE streaming responses in FastAPI
  - ChatMessage has role ("user"/"assistant") and content fields
  - ChatRequest has query, chat_history (optional), scene_id (optional), max_chunks
  - ChatChunk has delta (text content) and done (boolean) fields
  - StreamingResponse requires media_type="text/event-stream" for SSE
  - Set Cache-Control: no-cache, Connection: keep-alive, X-Accel-Buffering: no headers
  - Mock response word-by-word with asyncio.sleep(0.02) simulates LLM streaming

---

## 2025-02-05 - BRAIN-037A-02
- **What was implemented:**
  - RAG Integration was already implemented as part of BRAIN-037A-01
  - The chat endpoint calls RetrievalService with user query
  - Retrieved context is injected into the system prompt
  - Chat responses include formatted context from knowledge base
  - Shows number of relevant chunks found in response
- **Files changed:**
  - None (already implemented in BRAIN-037A-01)
- **Learnings for future iterations:**
  - RAG integration was done alongside the POST endpoint creation
  - RetrievalService.retrieve_relevant() is called with query and k chunks
  - Context is formatted as "[Source N: type:id]" followed by content
  - The system prompt is built with context when RAG is enabled

---

## 2025-02-05 - BRAIN-037A-03
- **What was implemented:**
  - Added ChatSessionStore for in-memory session-based chat history
  - Added session_id parameter to ChatRequest
  - Chat history is stored per session and retrieved on subsequent requests
  - Previous assistant response is included in RAG query for better context retrieval
  - Messages are saved to session after generation (user and assistant)
  - Response includes context indicator showing message count in session
- **Files changed:**
  - `src/api/routers/brain_settings.py` - Added ChatSessionStore, session_id, history tracking
- **Learnings for future iterations:**
  - In-memory storage is sufficient for development; production would use Redis/database
  - Session-based storage allows multi-turn conversations without client-side history
  - Including last assistant response in RAG query improves context retrieval
  - get_session() returns empty list for new sessions (no error handling needed)
  - Session ID defaults to "default" if not provided

---

## 2025-02-05 - BRAIN-037A-04
- **What was implemented:**
  - Streaming was already implemented as part of BRAIN-037A-01
  - SSE (Server-Sent Events) is used for streaming tokens
  - ChatChunk contains delta (text) and done (boolean) fields
  - Streaming works end-to-end with word-by-word mock response
- **Files changed:**
  - None (already implemented in BRAIN-037A-01)
- **Learnings for future iterations:**
  - SSE format: `data: {json}\n\n` for each chunk
  - StreamingResponse with media_type="text/event-stream" for SSE
  - AsyncIterator[str] is the return type for SSE generators
  - Client receives chunks as they're generated (real-time feedback)

---

## 2025-02-05 - BRAIN-037B-01
- **What was implemented:**
  - Created ChatInterface component as floating chat widget
  - Added fixed positioning (bottom-right) with toggle button
  - Collapsible panel with minimize/expand functionality
  - Integrated streaming chat API with real-time message updates
  - Added ChatMessage, ChatRequest, ChatChunk types to brainSettingsApi
  - Added `chat()` function to brainSettingsApi for streaming responses
  - Integrated ChatInterface into AppShell for global availability
  - Panel shows user messages (right-aligned) and AI responses (left-aligned)
  - Auto-scroll to latest message
  - Loading indicator with pulsing cursor during streaming
- **Files changed:**
  - `frontend/src/components/ChatInterface.tsx` - New component
  - `frontend/src/features/routing/api/brainSettingsApi.ts` - Added chat types and function
  - `frontend/src/components/composed/AppShell.tsx` - Added ChatInterface
- **Learnings for future iterations:**
  - Use type-only imports when `verbatimModuleSyntax` is enabled (e.g., `type ChatMessage`)
  - SSE streaming on frontend: Use `response.body?.getReader()` and TextDecoder
  - Parse SSE format: lines starting with `data: ` contain JSON payloads
  - AbortController allows canceling in-flight requests
  - The `cn` utility for className merging exists at `@/lib/utils`
  - Pre-existing typecheck errors in PromptsPage.tsx are unrelated to this story

---

## 2025-02-05 - BRAIN-037B-02
- **What was implemented:**
  - Message display was already implemented as part of BRAIN-037B-01
  - User messages: right-aligned (`ml-auto`), primary background color
  - AI messages: left-aligned (`mr-auto`), muted background color
  - Auto-scroll to latest message using useEffect with scrollRef
  - Input field with Enter key support (handleKeyDown callback)
  - Send button disabled during streaming and when input is empty
  - Streaming indicator with pulsing cursor (`â–Š`)
- **Files changed:**
  - None (functionality already in ChatInterface from BRAIN-037B-01)
- **Learnings for future iterations:**
  - ChatInterface was designed with all message display features from the start
  - User messages use `bg-primary text-primary-foreground` for contrast
  - AI messages use `bg-muted` for subtle differentiation
  - Auto-scroll uses `scrollTop = scrollHeight` pattern
  - Pulsing cursor created with `animate-pulse` Tailwind class

---

## 2025-02-05 - BRAIN-038-01
- **What was implemented:**
  - Created SmartTaggingService in knowledge context application services
  - TagCategory enum with: GENRE, MOOD, THEMES, CHARACTERS_PRESENT, LOCATIONS
  - GeneratedTag dataclass with category, value, confidence fields
  - TaggingResult with get_tags_by_category() and get_all_tags() helper methods
  - TaggingConfig dataclass with validation for configuration
  - LLM-based tag generation using JSON schema prompt
  - Tag value normalization (lowercase, stripped, hyphenated multi-word)
  - Content truncation for long texts (4000 char limit)
- **Files changed:**
  - `src/contexts/knowledge/application/services/smart_tagging_service.py` - New service
  - `src/contexts/knowledge/application/services/__init__.py` - Exported service and types
  - `tests/unit/contexts/knowledge/application/services/test_smart_tagging_service.py` - 14 tests, all passing
- **Learnings for future iterations:**
  - ILLMClient port uses `LLMRequest` with `system_prompt` and `user_prompt` fields (not `messages`)
  - LLMResponse has `text` field (not `content`), and method is `generate` (not `complete`)
  - Frozen dataclass with `__post_init__` is pattern for validation + immutability
  - Use `object.__setattr__(self, ...)` for modifying frozen dataclass in __post_init__

---

## 2025-02-05 - BRAIN-038-02
- **What was implemented:**
  - Tag categories were already implemented as part of BRAIN-038-01
  - TagCategory enum defines all required categories: genre, mood, themes, characters_present, locations
  - Category-specific prompts built via `_get_category_descriptions()` method
  - Each category includes description for prompt generation
- **Files changed:**
  - None (categories were part of SmartTaggingService from BRAIN-038-01)
- **Learnings for future iterations:**
  - Category descriptions are embedded in system prompt for LLM context
  - TagCategory enum provides type-safe category selection
  - Tags are automatically normalized to lowercase and hyphenated for consistency

---

## 2025-02-05 - BRAIN-038-03
- **What was implemented:**
  - Created SmartTaggingEventHandler for automatic tag generation on content events
  - Integrated with KnowledgeEventSubscriber to handle LoreCreated, LoreUpdated, SceneCreated, SceneUpdated events
  - Added async tag generation methods: _generate_and_store_lore_tags, _generate_and_store_scene_tags
  - Smart tags are merged with existing manual tags to preserve user edits
  - Enabled/disabled toggle for auto-tagging functionality
- **Files changed:**
  - `src/contexts/knowledge/application/event_handlers/smart_tagging_event_handler.py` - New handler with generate_tags_for_lore, generate_tags_for_scene, generate_tags_for_character methods
  - `src/contexts/knowledge/application/event_handlers/knowledge_event_subscriber.py` - Added tagging_handler integration and async tag generation
  - `src/contexts/knowledge/application/event_handlers/__init__.py` - Exported SmartTaggingEventHandler
  - `tests/unit/contexts/knowledge/application/event_handlers/test_smart_tagging_event_handler.py` - 15 comprehensive tests
- **Learnings for future iterations:**
  - KnowledgeEventSubscriber accepts optional tagging_handler parameter for dependency injection
  - SmartTaggingEventHandler uses _build_lore_content, _build_scene_content, _build_character_content to format content for tagging
  - Tags are stored as dict[str, list[str]] with category names as keys
  - Manual tags are preserved via _merge_tags which does set union of generated and existing tags
  - All 15 tests pass including end-to-end integration test

---

## 2025-02-05 - BRAIN-038-04
- **What was implemented:**
  - Added `metadata` field to Scene entity (narrative context) for flexible metadata storage
  - Added `metadata` field to Character aggregate (character context) for flexible metadata storage
  - Added smart tags methods to LoreEntry, Scene, and Character entities:
    - `set_smart_tags(tags: dict[str, list[str]])` - Store smart tags in metadata
    - `get_smart_tags() -> dict[str, list[str]]` - Retrieve smart tags
    - `has_smart_tag(category, tag)` - Check if specific tag exists (LoreEntry only)
    - `get_all_tags_combined()` - Get manual + smart tags combined (LoreEntry only)
  - Added metadata search methods to ILoreEntryRepository:
    - `find_by_smart_tag(category, tag, limit, offset)` - Find by single smart tag
    - `find_by_smart_tags(tags, match_all, limit)` - Find by multiple smart tags
    - `find_by_metadata(key, value, limit)` - Find by metadata key-value
  - Added metadata search methods to ICharacterRepository:
    - `find_by_smart_tag(category, tag, limit)` - Find by single smart tag
    - `find_by_smart_tags(tags, match_all, limit)` - Find by multiple smart tags
    - `find_by_metadata(key, value, limit)` - Find by metadata key-value
  - Added 24 comprehensive tests (8 per entity) for metadata and smart tags functionality
- **Files changed:**
  - `src/contexts/narrative/domain/entities/scene.py` - Added metadata field and smart tag methods
  - `src/contexts/character/domain/aggregates/character.py` - Added metadata field and smart tag methods
  - `src/contexts/world/domain/entities/lore_entry.py` - Added smart tag methods
  - `src/contexts/world/domain/repositories/lore_entry_repository.py` - Added metadata search methods
  - `src/contexts/character/domain/repositories/character_repository.py` - Added metadata search methods
  - `tests/unit/contexts/narrative/domain/entities/test_scene_entity.py` - 8 metadata tests
  - `tests/unit/contexts/character/domain/test_character_aggregate.py` - 8 metadata tests
  - `tests/unit/contexts/world/domain/test_lore_entry.py` - 8 smart tag tests
- **Learnings for future iterations:**
  - Scene already had `metadata: dict[str, Any]` field but it wasn't documented
  - Character's `metadata` field was added after `faction_id` to maintain dataclass field order
  - Smart tags are stored under `metadata["smart_tags"]` key to avoid conflicts with other metadata
  - Repository search methods use `Dict[str, List[str]]` type hint for tag filtering (match_all vs any)
  - LoreEntry already had manual `tags` field; smart tags are separate to allow auto-updating without overwriting user edits
  - Character is a frozen dataclass; metadata updates trigger version increment and domain events

---

## 2025-02-05 - BRAIN-038-05
- **What was implemented:**
  - Added `manual_smart_tags` tracking to LoreEntry, Scene, and Character entities
  - Manual tags are stored separately in `metadata["manual_smart_tags"]` to distinguish from auto-generated tags
  - Added entity methods: `set_manual_smart_tags()`, `get_manual_smart_tags()`, `get_manual_smart_tags_for_category()`, `remove_manual_smart_tag()`, `clear_manual_smart_tags()`, `get_effective_smart_tags()`
  - Updated SmartTaggingEventHandler to accept `manual_only_tags` parameter for preserving manual tags
  - Added new API schemas: `SmartTagsResponse`, `ManualSmartTagsUpdateRequest`
  - Added metadata field to LoreEntryResponse and SceneResponse
  - Added GET/PUT/DELETE endpoints for manual smart tags on lore entries and scenes
  - Created frontend `smartTagsApi.ts` API client and `SmartTagsEditor.tsx` UI component
  - SmartTagsEditor provides category-based tag editing with visual distinction between manual and auto tags
- **Files changed:**
  - `src/contexts/world/domain/entities/lore_entry.py` - Added manual smart tags methods
  - `src/contexts/narrative/domain/entities/scene.py` - Added manual smart tags methods
  - `src/contexts/character/domain/aggregates/character.py` - Added manual smart tags methods
  - `src/contexts/knowledge/application/event_handlers/smart_tagging_event_handler.py` - Updated to preserve manual tags
  - `src/api/schemas.py` - Added SmartTagsResponse, ManualSmartTagsUpdateRequest, metadata to responses
  - `src/api/routers/lore.py` - Added manual smart tags endpoints
  - `src/api/routers/structure.py` - Added manual smart tags endpoints for scenes, updated scene response
  - `frontend/src/features/routing/api/smartTagsApi.ts` - New API client
  - `frontend/src/components/narrative/SmartTagsEditor.tsx` - New UI component
  - `tests/unit/contexts/knowledge/application/event_handlers/test_manual_smart_tags.py` - 15 new tests
- **Learnings for future iterations:**
  - Manual tags are stored under a separate key (`manual_smart_tags`) to distinguish from auto-generated tags
  - The `get_effective_smart_tags()` method combines both auto and manual tags
  - UI shows manual tags with a lock icon and removal button, auto tags are read-only
  - SmartTaggingEventHandler's `_merge_tags` now accepts `manual_only_tags` to always preserve them
  - When auto-tagging runs, existing manual tags are preserved and merged with newly generated tags
  - Character's `set_manual_smart_tags()` triggers domain event and version increment (frozen dataclass)
  - All 15 tests pass: 9 for LoreEntry, 3 for Scene, 3 for Character

---

## 2025-02-05 - BRAIN-039A-01
- **What was implemented:**
  - Created IChunkingStrategy port interface in knowledge context application layer
  - Added Chunk domain entity with text, index, and metadata fields
  - Added ChunkingError exception with default and custom error codes
  - Port defines async chunk(text, config) -> list[Chunk] method
  - Port defines supports_strategy_type(strategy_type) -> bool method
  - Chunk entity has equality, hash, and repr implementations for use in collections
- **Files changed:**
  - `src/contexts/knowledge/application/ports/i_chunking_strategy.py` - New port interface
  - `tests/unit/contexts/knowledge/application/ports/test_i_chunking_strategy.py` - 20 comprehensive tests
- **Learnings for future iterations:**
  - Existing codebase already has TextChunker domain service and ChunkingStrategy value object
  - This port provides hexagonal architecture abstraction over existing TextChunker
  - Chunk entity is a domain entity (not frozen) with mutable metadata dict
  - Chunk equality and hash based on text + index enables use in sets/dicts
  - The existing TextChunker service can be adapted to implement this port
  - Import path: use absolute `from src.contexts.knowledge.domain.models...` not relative

---

## 2025-02-05 - BRAIN-039A-02
- **What was implemented:**
  - Created FixedChunkingStrategy adapter implementing IChunkingStrategy port
  - Fixed-size chunking with configurable chunk_size and overlap parameters
  - async chunk() method that returns list[Chunk] entities
  - Metadata tracking: word_count, start_char, end_char, chunk_size, overlap, strategy
  - supports_strategy_type() method returns True for "fixed" strategy type
  - Character position tracking for chunk boundaries in metadata
  - Custom default config support via constructor parameter
- **Files changed:**
  - `src/contexts/knowledge/infrastructure/adapters/chunking_strategy_adapters.py` (new)
  - `src/contexts/knowledge/infrastructure/adapters/__init__.py` - Exported FixedChunkingStrategy
  - `tests/unit/contexts/knowledge/infrastructure/adapters/test_chunking_strategy_adapters.py` (new)
- **Learnings for future iterations:**
  - Chunking adapters go in infrastructure/adapters, not application/services
  - Word pattern `\S+` matches any non-whitespace characters for word counting
  - Overlap creates context continuity: second chunk starts at (chunk_size - overlap)
  - The effective_chunk_size() = chunk_size - overlap determines stride
  - With overlap, total word count across all chunks will be higher than input word count
  - Character position tracking uses regex finditer for accurate positions
  - All 27 tests pass including edge cases: empty text, single word, zero/large overlap
  - Existing TextChunker domain service has similar logic but this follows hexagonal architecture

---
