{
  "project": "Novel-Engine-Op-Synapse",
  "branchName": "refactor/brain-optimization",
  "description": "OPERATION SYNAPSE: Refactoring the AI Brain for performance, accuracy, and maintainability before World Simulation.",
  "techContext": {
    "stack": "FastAPI + ChromaDB + Redis (mocked) + React (shadcn/ui + Zustand)",
    "testCommand": "pytest && npm --prefix frontend run test:e2e",
    "typecheckCommand": "mypy --strict src/contexts/knowledge && npm --prefix frontend run type-check",
    "conventions": "Strict Hexagonal Architecture, contract-first (schemas -> OpenAPI -> frontend types), structured logging via structlog, shadcn/ui + Tailwind-only styling, and required UI states (loading/empty/error/ready). Extract large classes into composable strategies."
  },
  "userStories": [
    {
      "id": "OPT-001",
      "title": "Backend: Ingestion Processor Abstraction",
      "description": "Split KnowledgeIngestionService into composable processors without behavior changes.",
      "acceptanceCriteria": [
        "Create an application-layer processor interface (e.g., IIngestionProcessor) and a factory mapping SourceType -> processor with a GenericProcessor fallback.",
        "Implement LoreProcessor, SceneProcessor, CharacterProcessor that only define chunking defaults + metadata enrichment (no embedding/store logic).",
        "KnowledgeIngestionService delegates chunking + entry creation to the processor while keeping embedding + vector store logic intact.",
        "Add unit tests verifying processor selection and no regressions in tests/unit/contexts/knowledge/application/services/test_knowledge_ingestion_service.py."
      ],
      "priority": 1,
      "passes": true,
      "effort": "medium",
      "notes": "Keep SRP: processor handles content-specific behavior, service orchestrates pipeline."
    },
    {
      "id": "OPT-002",
      "title": "Backend: Embedding Cache Layer",
      "description": "Avoid repeat embedding calls with a cache wrapper prepared for Redis.",
      "acceptanceCriteria": [
        "Create EmbeddingCacheService with LRU + TTL (reuse src/caching/exact_cache.py or a typed LRU) and sha256(text + model) keys.",
        "Add CachedEmbeddingService adapter implementing IEmbeddingService that wraps a delegate and uses EmbeddingCacheService for embed/embed_batch.",
        "Remove or disable EmbeddingServiceAdapter's internal cache (or make it pluggable) to avoid double caching and TTL mismatch.",
        "Add unit tests for cache hits, TTL expiration, batch caching, and structured logs for cache_hit/cache_miss."
      ],
      "priority": 2,
      "passes": true,
      "effort": "medium",
      "notes": "Design cache API to allow a Redis-backed implementation later."
    },
    {
      "id": "OPT-003",
      "title": "AI: RAG Re-ranking Integration",
      "description": "Wire the existing RerankService into the retrieval pipeline.",
      "acceptanceCriteria": [
        "Inject RerankService into RetrievalService and apply reranking after filtering/deduplication.",
        "Add RetrievalOptions fields for candidate_k (e.g., 20) and final_k (e.g., 5) to support retrieve->rerank->trim.",
        "On rerank failure, fall back to original order and emit a structured warning log.",
        "Add unit tests covering rerank success, fallback path, and candidate/final top-k behavior using the mock reranker."
      ],
      "priority": 3,
      "passes": true,
      "effort": "high",
      "notes": "Reuse src/contexts/knowledge/application/services/rerank_service.py and adapters; do not re-implement reranking."
    },
    {
      "id": "OPT-004",
      "title": "Frontend: Chat Virtualization",
      "description": "Keep chat smooth with long histories.",
      "acceptanceCriteria": [
        "Refactor frontend/src/components/ChatInterface.tsx to use virtualization (prefer react-window already in deps; add react-virtuoso only if dynamic heights are too complex).",
        "Support dynamic-height messages and preserve auto-scroll + streaming updates.",
        "Use shared cn utility (frontend/src/lib/utils.ts) and keep shadcn/ui + Tailwind-only styling; no custom CSS.",
        "Verify loading/empty/error/ready states still render correctly with 100+ messages."
      ],
      "priority": 4,
      "passes": false,
      "effort": "medium",
      "notes": "Avoid deep nesting; keep layout within 3 levels."
    },
    {
      "id": "OPT-005",
      "title": "Backend: Async Ingestion Job API",
      "description": "Run ingestion in the background and expose status.",
      "acceptanceCriteria": [
        "Add POST /api/brain/ingestion to start ingestion via FastAPI BackgroundTasks and return 202 + job_id.",
        "Add in-memory job store and GET /api/brain/ingestion/{job_id} to return status/progress/errors.",
        "Reuse KnowledgeSyncEventHandler or KnowledgeIngestionService for the worker path without blocking the request thread.",
        "Update src/api/schemas.py, regenerate docs/api/openapi.json, and sync frontend/src/types/schemas.ts; add unit tests for 202 + status transitions."
      ],
      "priority": 5,
      "passes": false,
      "effort": "medium",
      "notes": "Keep router thin; business logic in application services."
    },
    {
      "id": "OPT-006",
      "title": "Domain: Structured Metadata Schema",
      "description": "Replace unstructured metadata dicts with a strict schema.",
      "acceptanceCriteria": [
        "Introduce KnowledgeMetadata value object (domain) + a Pydantic schema for API/migrations with fields: world_version, confidentiality_level, last_accessed (UTC), source_version.",
        "Update SourceMetadata/SourceKnowledgeEntry to include structured metadata while preserving existing extra fields.",
        "Create a mock migration script to backfill missing metadata fields for existing vector documents.",
        "Add unit tests ensuring defaults, serialization, and timezone handling are stable."
      ],
      "priority": 6,
      "passes": false,
      "effort": "low",
      "notes": "Preserve backward compatibility for existing extra metadata keys."
    },
    {
      "id": "OPT-007",
      "title": "Test: Golden Dataset Evaluation Harness",
      "description": "Automated QA to ensure RAG accuracy doesnâ€™t regress.",
      "acceptanceCriteria": [
        "Create tests/evaluation/golden_dataset.json with at least 20 question -> expected fact pairs.",
        "Add scripts/evaluation/run_golden_dataset.py to run retrieval + rerank and score exact/substring/fuzzy match (SequenceMatcher is OK).",
        "Add tests/evaluation/test_golden_dataset.py that asserts a baseline score and prints a short report.",
        "Use deterministic embeddings + an in-memory vector store fixture so results are stable in CI."
      ],
      "priority": 7,
      "passes": false,
      "effort": "high",
      "notes": "Keep the dataset small and curated; avoid flaky tests."
    },
    {
      "id": "OPT-008",
      "title": "UX: Markdown + Code Highlighting in Chat",
      "description": "Improve readability of AI responses.",
      "acceptanceCriteria": [
        "Add a Markdown renderer component using markdown-it with safe HTML settings (no raw HTML by default).",
        "Enable code block highlighting (add highlight.js or prismjs if needed) and style using Tailwind classes only.",
        "Render assistant messages with Markdown; user messages stay plain text.",
        "Verify tables, lists, and code blocks render correctly in ChatInterface."
      ],
      "priority": 8,
      "passes": false,
      "effort": "low",
      "notes": "No custom CSS files; shadcn/ui where appropriate."
    },
    {
      "id": "OPT-009",
      "title": "Backend: Context Window Manager",
      "description": "Prevent context window overflow by pruning intelligently.",
      "acceptanceCriteria": [
        "Create ContextWindowManager that uses ContextOptimizer + TokenCounter to fit within model token limits.",
        "Priority order: System Prompt > RAG Chunks > Recent History (oldest first pruned).",
        "Integrate into /api/brain/chat prompt assembly (and optionally RAGIntegrationService) so prompts never exceed limits.",
        "Add unit tests simulating overflow scenarios and verifying pruning order."
      ],
      "priority": 9,
      "passes": false,
      "effort": "high",
      "notes": "Use existing token_counter/context_optimizer modules; avoid new tokenizers."
    },
    {
      "id": "OPT-010",
      "title": "Codebase: Mypy Strictness Audit (Knowledge)",
      "description": "Eliminate implicit Any in knowledge context.",
      "acceptanceCriteria": [
        "Run mypy --strict on src/contexts/knowledge and fix all type errors.",
        "Address Result<T,E> generics and Optional handling in application services.",
        "Add or update mypy config as needed without relaxing strictness.",
        "Document any unavoidable ignores with justification."
      ],
      "priority": 10,
      "passes": false,
      "effort": "medium",
      "notes": "No blanket ignores; keep scope tight to knowledge context."
    },
    {
      "id": "OPT-011",
      "title": "Frontend: Optimistic Updates for Smart Tags",
      "description": "Make tagging feel instant with rollback on failure.",
      "acceptanceCriteria": [
        "Refactor SmartTagsEditor to use @tanstack/react-query hooks for fetch + mutations.",
        "Implement onMutate optimistic updates with rollback on error and consistent toast messaging.",
        "Ensure UI states (loading/empty/error/ready) are preserved during optimistic updates.",
        "Add a unit/integration test for optimistic update behavior or cover via e2e smoke."
      ],
      "priority": 11,
      "passes": false,
      "effort": "medium",
      "notes": "Remove direct fetch calls in the component; centralize in hooks."
    },
    {
      "id": "OPT-012",
      "title": "Integration: Local Model Prompt Strategy",
      "description": "Support DeepSeek/Llama prompt formats without OpenAI assumptions.",
      "acceptanceCriteria": [
        "Add prompt templates optimized for DeepSeek-Coder and Llama-3 in the prompt repository/migration flow.",
        "Extend ModelRouter or prompt selection logic to choose templates by model family/provider.",
        "Add tests verifying rendered prompt format for non-OpenAI models.",
        "If API config changes, update schemas/openapi/front-end types accordingly."
      ],
      "priority": 12,
      "passes": false,
      "effort": "medium",
      "notes": "Keep prompt strategy selection in application layer; no UI coupling."
    },
    {
      "id": "OPT-013",
      "title": "Docs: RAG Architecture Diagram",
      "description": "Document the brain pipeline for onboarding and reviews.",
      "acceptanceCriteria": [
        "Create docs/architecture/rag_pipeline.mermaid showing Ingestion -> Chunking -> Embedding -> Retrieval -> Rerank -> Generation.",
        "Link the diagram from docs/index.md and README.md.",
        "Ensure component names match current code (KnowledgeIngestionService, RetrievalService, RerankService)."
      ],
      "priority": 13,
      "passes": false,
      "effort": "low",
      "notes": "Keep the diagram minimal and accurate."
    },
    {
      "id": "OPT-014",
      "title": "Security: API Key Storage Hardening",
      "description": "Ensure API keys are never stored or exposed in plaintext.",
      "acceptanceCriteria": [
        "Require BRAIN_SETTINGS_ENCRYPTION_KEY (log a warning if unset) and remove random fallback behavior.",
        "Audit brain_settings repository to guarantee encrypted-at-rest storage and masked responses only.",
        "Add unit tests verifying encrypted storage, masked output, and no raw keys in logs.",
        "Update README.md/SECURITY.md with configuration requirement and rotation guidance."
      ],
      "priority": 14,
      "passes": false,
      "effort": "medium",
      "notes": "No DB persistence required; focus on safety + tests."
    },
    {
      "id": "OPT-015",
      "title": "E2E: Chat Stress + Resilience",
      "description": "Break the chat and verify recovery.",
      "acceptanceCriteria": [
        "Create tests/e2e/chat-stress.spec.ts with rapid-fire message simulation (50+ messages).",
        "Simulate network interruption during streaming and verify error state + recovery flow.",
        "Ensure message order remains stable and UI remains responsive.",
        "Tag test for e2e and include in npm --prefix frontend run test:e2e."
      ],
      "priority": 15,
      "passes": false,
      "effort": "high",
      "notes": "Use Playwright route interception to simulate network faults."
    }
  ]
}
