{
  "project": "Novel-Engine-Warzone-4-AI-Brain",
  "branchName": "feat/code-citadel",
  "description": "WARZONE 4: Building the RAG (Retrieval-Augmented Generation) engine and Prompt Engineering Lab. Enabling long-term memory for the AI system through ChromaDB vector storage, multi-LLM support, and knowledge graph capabilities.",
  "techContext": {
    "stack": "FastAPI + ChromaDB + OpenAI/Anthropic/Gemini + React",
    "testCommand": "pytest tests/ && npm run test:e2e",
    "typecheckCommand": "mypy . && npm run type-check",
    "conventions": "TDD/BDD approach: Write failing test first, implement minimum code, verify with E2E. Strict adherence to CONVENTIONS.md (Hexagonal Arch) and DESIGN_SYSTEM.md."
  },
  "userStories": [
    {
      "id": "BRAIN-001",
      "title": "Infra: Setup Vector Database (ChromaDB)",
      "description": "Initialize the long-term memory storage for the AI system.",
      "acceptanceCriteria": [
        "Install `chromadb` and `tiktoken` dependencies",
        "Create `VectorStore` adapter in `infrastructure/adapters/vector_store/`",
        "Implement `IVectorStore` port with methods: upsert, query, delete, clear",
        "Support persistent storage in `.data/chroma/` directory",
        "Add health check endpoint to verify ChromaDB connection",
        "Test: Verify data persistence across restarts using temporary local folder"
      ],
      "priority": 1,
      "passes": true,
      "effort": "medium"
    },
    {
      "id": "BRAIN-002",
      "title": "Infra: Embedding Service Adapter",
      "description": "Convert text to vectors for semantic search.",
      "acceptanceCriteria": [
        "Create `EmbeddingService` adapter wrapping OpenAI `text-embedding-3-small`",
        "Implement `IEmbeddingPort` with `embed(text: str) -> list[float]` method",
        "Add batch embedding support for efficiency",
        "Implement fallback mock embedding for testing (deterministic random vectors)",
        "Add dimension configuration (default: 1536 for OpenAI)",
        "Test: Verify vectors have correct dimensions and are deterministic for same input"
      ],
      "priority": 2,
      "passes": true,
      "effort": "low",
      "dependencies": [
        "BRAIN-001"
      ]
    },
    {
      "id": "BRAIN-003",
      "title": "Domain: Knowledge Entry Entity",
      "description": "Define the unit of memory storage.",
      "acceptanceCriteria": [
        "Create `KnowledgeEntry` entity with: id, content, source_type (CHARACTER/LORE/SCENE/PLOTLINE), source_id, metadata, embedding_id",
        "Define `ChunkingStrategy` value object: chunk_size, overlap, strategy (FIXED/SEMANTIC)",
        "Implement chunker that splits long text into overlapping chunks",
        "Add metadata enrichment (timestamp, word_count, tags)",
        "Test: Split a 2000-word text into chunks with 500-word size and 50-word overlap"
      ],
      "priority": 3,
      "passes": true,
      "effort": "medium"
    },
    {
      "id": "BRAIN-004",
      "title": "Service: Knowledge Ingestion Service",
      "description": "Feed knowledge into the vector database.",
      "acceptanceCriteria": [
        "Create `KnowledgeIngestionService` in knowledge context",
        "Method `ingest(entity)`: Text -> Chunk -> Embed -> Store in Chroma",
        "Method `batch_ingest(entities)`: Efficient bulk processing",
        "Method `delete(source_id)`: Remove all chunks for a source",
        "Method `update(source_id, content)`: Replace old chunks with new",
        "Add progress tracking for large ingestions",
        "Test: Ingest a Character Profile and verify it's queryable by content"
      ],
      "priority": 4,
      "passes": true,
      "effort": "high",
      "dependencies": [
        "BRAIN-002",
        "BRAIN-003"
      ]
    },
    {
      "id": "BRAIN-005",
      "title": "Integration: Auto-Sync Event Listeners",
      "description": "Keep memory fresh automatically by listening to domain events.",
      "acceptanceCriteria": [
        "Create domain event handlers for: CharacterCreated, CharacterUpdated, LoreCreated, LoreUpdated, SceneCreated, SceneUpdated",
        "Handlers trigger `KnowledgeIngestionService.ingest()` on events",
        "Add async processing queue for ingestions to avoid blocking",
        "Add error handling and retry logic for failed ingestions",
        "Test: Create a character via API and verify vectors appear in ChromaDB"
      ],
      "priority": 5,
      "passes": true,
      "effort": "medium",
      "dependencies": [
        "BRAIN-004"
      ]
    },
    {
      "id": "BRAIN-006",
      "title": "Service: Context Retrieval Service (RAG)",
      "description": "The 'Recall' mechanism for fetching relevant knowledge.",
      "acceptanceCriteria": [
        "Create `RetrievalService` in knowledge context",
        "Method `retrieve_relevant(query: str, k: int = 5, filters: dict)`: Search VectorDB",
        "Method `format_context(results, max_tokens)`: Convert results to LLM prompt block",
        "Support filtering by source_type, tags, date ranges",
        "Add relevance score threshold to filter low-quality results",
        "Implement deduplication of similar chunks",
        "Test: Search for 'brave warrior' and get relevant character with that trait"
      ],
      "priority": 6,
      "passes": true,
      "effort": "medium",
      "dependencies": [
        "BRAIN-004"
      ]
    },
    {
      "id": "BRAIN-007",
      "title": "Integration: RAG-Enhanced Generation",
      "description": "Inject retrieved memory into AI generation.",
      "acceptanceCriteria": [
        "Update `LLMWorldGenerator` methods (generate_scene, generate_beat)",
        "Step 1: Extract keywords/summary from request",
        "Step 2: Call `RetrievalService.retrieve_relevant()`",
        "Step 3: Inject retrieved context into System Prompt as 'Relevant Context:' section",
        "Add toggle to enable/disable RAG per request",
        "Log number of chunks retrieved and tokens added",
        "Test: Mock retrieval and verify prompt structure contains context"
      ],
      "priority": 7,
      "passes": false,
      "effort": "high",
      "dependencies": [
        "BRAIN-006"
      ]
    },
    {
      "id": "BRAIN-008",
      "title": "RAG: Hybrid Search (Vector + BM25)",
      "description": "Combine semantic search with keyword search for better results.",
      "acceptanceCriteria": [
        "Implement BM25 keyword search using rank-bm25 or similar",
        "Create `HybridRetriever` that combines vector and BM25 scores",
        "Configurable weight between vector (default 0.7) and BM25 (default 0.3)",
        "Add alpha parameter for score fusion (Reciprocal Rank Fusion)",
        "Test: Compare pure vector vs hybrid search quality"
      ],
      "priority": 8,
      "passes": false,
      "effort": "high",
      "dependencies": [
        "BRAIN-006"
      ]
    },
    {
      "id": "BRAIN-009",
      "title": "RAG: Query Rewriting & Expansion",
      "description": "Improve retrieval by rewriting user queries.",
      "acceptanceCriteria": [
        "Implement `QueryRewriter` service using LLM",
        "Strategies: Synonym expansion, sub-query decomposition, clarification",
        "Method `rewrite(query: str) -> list[str]` returns multiple query variants",
        "Execute retrieval for all variants and merge results",
        "Add caching for rewritten queries to save tokens",
        "Test: Query 'protagonist motivation' expands to include character name"
      ],
      "priority": 9,
      "passes": false,
      "effort": "medium",
      "dependencies": [
        "BRAIN-006"
      ]
    },
    {
      "id": "BRAIN-010",
      "title": "RAG: Re-ranking Service",
      "description": "Re-rank retrieved results for better relevance.",
      "acceptanceCriteria": [
        "Implement re-ranking using Cohere Rerank API or local cross-encoder",
        "Create `RerankService` with `rerank(query, results, top_k)` method",
        "Support both API-based (Cohere) and local (sentence-transformers) rerankers",
        "Add fallback to original order if reranking fails",
        "Track reranking latency and score improvements",
        "Test: Verify top-3 results improve after reranking"
      ],
      "priority": 10,
      "passes": false,
      "effort": "high",
      "dependencies": [
        "BRAIN-008"
      ]
    },
    {
      "id": "BRAIN-011",
      "title": "RAG: Context Window Optimization",
      "description": "Fit as much relevant context as possible within token limits.",
      "acceptanceCriteria": [
        "Implement `ContextOptimizer` that packs chunks efficiently",
        "Strategies: Remove redundancy, prioritize high-relevance, compress summaries",
        "Reserve tokens for system prompt and generation (calculate available space)",
        "Add token counting using tiktoken before sending to LLM",
        "Method `optimize_context(chunks, max_tokens)` returns optimal subset",
        "Test: Verify packed context stays under token limit"
      ],
      "priority": 11,
      "passes": false,
      "effort": "medium",
      "dependencies": [
        "BRAIN-006"
      ]
    },
    {
      "id": "BRAIN-012",
      "title": "RAG: Citation & Source Attribution",
      "description": "Show where retrieved information comes from.",
      "acceptanceCriteria": [
        "Add source tracking to all retrieved chunks (source_type, source_id, chunk_index)",
        "Implement citation formatter that generates [Source: Character:alice] markers",
        "Insert citations into generated text at appropriate positions",
        "Create `get_sources(context)` method to list all sources for a response",
        "UI: Render citations as clickable links in the interface",
        "Test: Verify each fact in response has correct source"
      ],
      "priority": 12,
      "passes": false,
      "effort": "medium",
      "dependencies": [
        "BRAIN-006"
      ]
    },
    {
      "id": "BRAIN-013",
      "title": "RAG: Multi-Hop Reasoning",
      "description": "Enable complex queries requiring multiple retrieval steps.",
      "acceptanceCriteria": [
        "Implement `MultiHopRetriever` for chained reasoning",
        "Decompose complex queries into sub-queries",
        "Use results from first hop to inform second hop query",
        "Example: 'Who is the villain that killed the king?' -> Find king's killer -> Get their details",
        "Add max_hops limit (default 3) to prevent infinite loops",
        "Log reasoning chain for debugging",
        "Test: Verify multi-hop question returns correct answer"
      ],
      "priority": 13,
      "passes": false,
      "effort": "high",
      "dependencies": [
        "BRAIN-010"
      ]
    },
    {
      "id": "BRAIN-014",
      "title": "Domain: Prompt Template Entity",
      "description": "Treat prompts as versioned, manageable code.",
      "acceptanceCriteria": [
        "Create `PromptTemplate` entity: id, name, content, variables ({{var}}), model_config, version, created_at",
        "Define `VariableDefinition`: name, type, default_value, description",
        "Create `IPromptRepository` port for CRUD operations",
        "Migrate existing hardcoded prompts from YAML to DB",
        "Add template validation (undefined variables, syntax errors)",
        "Support nested includes ({{> other_prompt}})",
        "Test: CRUD operations on prompt templates"
      ],
      "priority": 14,
      "passes": false,
      "effort": "medium"
    },
    {
      "id": "BRAIN-015",
      "title": "Backend: Prompt Management API",
      "description": "REST API for managing prompt templates.",
      "acceptanceCriteria": [
        "Create `routers/prompts.py` with full CRUD endpoints",
        "GET /api/prompts - List all prompts with filtering",
        "POST /api/prompts - Create new prompt template",
        "GET /api/prompts/{id} - Get specific prompt",
        "PUT /api/prompts/{id} - Update prompt (creates new version)",
        "DELETE /api/prompts/{id} - Archive (soft delete) prompt",
        "POST /api/prompts/{id}/render - Render prompt with variables",
        "Test: Verify variable substitution and validation"
      ],
      "priority": 15,
      "passes": false,
      "effort": "low",
      "dependencies": [
        "BRAIN-014"
      ]
    },
    {
      "id": "BRAIN-016",
      "title": "Prompt: Version Control & History",
      "description": "Track changes to prompts over time.",
      "acceptanceCriteria": [
        "Extend `PromptTemplate` with version field and parent_version_id",
        "Create `PromptVersion` entity linking to previous versions",
        "GET /api/prompts/{id}/versions - List all versions",
        "POST /api/prompts/{id}/rollback/{version} - Restore previous version",
        "Add diff view between versions (character-level diff)",
        "Test: Create versions and verify rollback works"
      ],
      "priority": 16,
      "passes": false,
      "effort": "medium",
      "dependencies": [
        "BRAIN-015"
      ]
    },
    {
      "id": "BRAIN-017",
      "title": "Prompt: Template Inheritance & Composition",
      "description": "Build complex prompts from reusable components.",
      "acceptanceCriteria": [
        "Add `extends` field to `PromptTemplate` for inheritance",
        "Support `{{> base_prompt}}` syntax for including other prompts",
        "Child templates can override parent variables",
        "Allow multiple inheritance (composition of several base prompts)",
        "Circular dependency detection in extends chain",
        "Test: Create base prompt and extend it with child"
      ],
      "priority": 17,
      "passes": false,
      "effort": "medium",
      "dependencies": [
        "BRAIN-014"
      ]
    },
    {
      "id": "BRAIN-018",
      "title": "Prompt: A/B Testing Framework",
      "description": "Compare prompt variants to find best performing.",
      "acceptanceCriteria": [
        "Create `PromptExperiment` entity: id, prompt_a_id, prompt_b_id, metric, traffic_split, status",
        "Implement experiment assignment logic (consistent hashing for user/session)",
        "Track metrics: success_rate, user_rating, token_efficiency, latency",
        "POST /api/prompts/experiments - Create A/B test",
        "GET /api/prompts/experiments/{id}/results - View experiment results",
        "Statistical significance calculation for winner declaration",
        "Test: Run experiment and verify traffic split"
      ],
      "priority": 18,
      "passes": false,
      "effort": "high",
      "dependencies": [
        "BRAIN-015"
      ]
    },
    {
      "id": "BRAIN-019",
      "title": "Frontend: Prompt Engineering Lab UI",
      "description": "The IDE for creating and editing prompts.",
      "acceptanceCriteria": [
        "Create `/brain/prompts` route with main list view",
        "UI: List of all prompts with search and filter",
        "UI: Prompt editor with textarea and syntax highlighting for {{variables}}",
        "UI: Variable definition table (name, type, default, description)",
        "UI: Model configuration selector (temperature, max_tokens)",
        "UI: Version history sidebar",
        "Autosave draft to localStorage",
        "Test: Create, edit, and save a prompt"
      ],
      "priority": 19,
      "passes": false,
      "effort": "medium",
      "dependencies": [
        "BRAIN-015"
      ]
    },
    {
      "id": "BRAIN-020",
      "title": "Frontend: Prompt Playground",
      "description": "Test prompts before deploying.",
      "acceptanceCriteria": [
        "Add 'Run' button in Prompt Editor that opens Playground modal",
        "UI: Form fields for all variables defined in prompt",
        "UI: Model selector and parameters (temperature, etc.)",
        "Action: Call backend /api/prompts/{id}/render and /api/generate",
        "UI: Split view - rendered prompt on left, LLM output on right",
        "Token count display for rendered prompt and response",
        "Copy to clipboard button for output",
        "Test: Run prompt with variables and see output"
      ],
      "priority": 20,
      "passes": false,
      "effort": "high",
      "dependencies": [
        "BRAIN-019"
      ]
    },
    {
      "id": "BRAIN-021",
      "title": "Frontend: Prompt Comparison View",
      "description": "Side-by-side comparison of prompt variants.",
      "acceptanceCriteria": [
        "Add 'Compare' mode in Prompt Lab",
        "UI: Select two prompt versions to compare",
        "Side-by-side diff view of prompt content",
        "Variable comparison table",
        "Model config diff view",
        "One-click swap for testing",
        "Test: Compare two versions and see differences highlighted"
      ],
      "priority": 21,
      "passes": false,
      "effort": "medium",
      "dependencies": [
        "BRAIN-020"
      ]
    },
    {
      "id": "BRAIN-022",
      "title": "Backend: Prompt Analytics (Success Rate)",
      "description": "Track how well prompts perform.",
      "acceptanceCriteria": [
        "Create `PromptUsage` entity: prompt_id, timestamp, tokens, latency, user_rating",
        "Log usage for every prompt generation",
        "GET /api/prompts/{id}/analytics - Usage stats over time",
        "Metrics: Total uses, avg tokens, avg latency, rating distribution",
        "Aggregate by time period (day/week/month)",
        "Export analytics as CSV",
        "Test: Generate with prompt and verify analytics recorded"
      ],
      "priority": 22,
      "passes": false,
      "effort": "medium",
      "dependencies": [
        "BRAIN-018"
      ]
    },
    {
      "id": "BRAIN-023",
      "title": "Domain: Model Registry",
      "description": "Support multiple LLM providers and models.",
      "acceptanceCriteria": [
        "Create `LLMProvider` enum: OPENAI, ANTHROPIC, GEMINI, OLLAMA, MOCK",
        "Create `ModelConfig` value object: provider, model_name, api_key_ref, base_url, max_tokens, supports_functions",
        "Create `ModelRegistry` service to manage available models",
        "Add per-task default model config (CREATIVE, LOGICAL, FAST, CHEAP)",
        "Config file for model aliases (gpt4 -> OPENAI:gpt-4-turbo)",
        "Test: Switch between models dynamically"
      ],
      "priority": 23,
      "passes": false,
      "effort": "medium"
    },
    {
      "id": "BRAIN-024",
      "title": "LLM: Anthropic Claude Integration",
      "description": "Add Claude as an LLM option.",
      "acceptanceCriteria": [
        "Create `ClaudeAdapter` implementing `ILLMPort`",
        "Support Claude 3 Opus, Sonnet, Haiku models",
        "Implement message format conversion (Claude uses different format than OpenAI)",
        "Support streaming responses",
        "Handle Claude's token counting differently",
        "Test: Generate text using Claude Sonnet"
      ],
      "priority": 24,
      "passes": false,
      "effort": "high",
      "dependencies": [
        "BRAIN-023"
      ]
    },
    {
      "id": "BRAIN-025",
      "title": "LLM: Google Gemini Integration",
      "description": "Add Google Gemini as an LLM option.",
      "acceptanceCriteria": [
        "Create `GeminiAdapter` implementing `ILLMPort`",
        "Support Gemini Pro and Gemini Ultra models",
        "Handle Gemini's chat history format",
        "Support multimodal inputs (text + images)",
        "Configure safety settings",
        "Test: Generate text using Gemini Pro"
      ],
      "priority": 25,
      "passes": false,
      "effort": "high",
      "dependencies": [
        "BRAIN-023"
      ]
    },
    {
      "id": "BRAIN-026",
      "title": "LLM: OpenAI GPT-4 Turbo Integration",
      "description": "Upgrade to latest OpenAI models.",
      "acceptanceCriteria": [
        "Update `OpenAIAdapter` to support GPT-4 Turbo and GPT-4o",
        "Add support for vision capabilities (GPT-4o)",
        "Implement parallel function calling",
        "Add support for JSON mode",
        "Configure lower temperature for JSON outputs",
        "Test: Generate structured JSON using GPT-4o"
      ],
      "priority": 26,
      "passes": false,
      "effort": "medium",
      "dependencies": [
        "BRAIN-023"
      ]
    },
    {
      "id": "BRAIN-027",
      "title": "Integration: Local LLM Support (Ollama)",
      "description": "Privacy-first local model support.",
      "acceptanceCriteria": [
        "Create `OllamaAdapter` implementing `ILLMPort`",
        "Config: Base URL (localhost:11434) and model name",
        "Support popular local models: Llama 3, Mistral, Phi-3",
        "Auto-detect available Ollama models via /api/tags",
        "Connection check endpoint",
        "Handle Ollama's streaming format",
        "Test: Generate text using local Llama 3"
      ],
      "priority": 27,
      "passes": false,
      "effort": "high",
      "dependencies": [
        "BRAIN-023"
      ]
    },
    {
      "id": "BRAIN-028",
      "title": "LLM: Model Routing Strategy",
      "description": "Automatically select best model for each task.",
      "acceptanceCriteria": [
        "Create `ModelRouter` service with routing logic",
        "Routes based on: task type, complexity, cost budget, latency requirement",
        "Implement fallback chain (primary -> secondary -> mock)",
        "Add circuit breaker for failing models",
        "Log routing decisions for analytics",
        "Configurable routing rules per workspace",
        "Test: Verify correct model selection per task type"
      ],
      "priority": 28,
      "passes": false,
      "effort": "medium",
      "dependencies": [
        "BRAIN-024",
        "BRAIN-025",
        "BRAIN-026"
      ]
    },
    {
      "id": "BRAIN-029",
      "title": "KG: Entity Extraction Service",
      "description": "Extract entities (people, places, things) from text.",
      "acceptanceCriteria": [
        "Create `EntityExtractionService` in knowledge context",
        "Extract: Characters, Locations, Items, Events, Organizations",
        "Use LLM with structured output for extraction",
        "Return entities with: name, type, aliases, first_appearance",
        "Handle entity co-reference (he -> Alice)",
        "Batch processing for large texts",
        "Test: Extract all named entities from a chapter"
      ],
      "priority": 29,
      "passes": false,
      "effort": "high"
    },
    {
      "id": "BRAIN-030",
      "title": "KG: Relationship Extraction",
      "description": "Extract relationships between entities.",
      "acceptanceCriteria": [
        "Extend entity extraction to capture relationships",
        "Relationship types: KNOWS, KILLED, LOVES, HATES, PARENT_OF, MEMBER_OF",
        "Create `Relationship` entity: source, target, type, context, strength",
        "Bidirectional relationship normalization",
        "Temporal relationships (valid at specific time in story)",
        "Test: Extract 'Alice killed Bob' relationship"
      ],
      "priority": 30,
      "passes": false,
      "effort": "high",
      "dependencies": [
        "BRAIN-029"
      ]
    },
    {
      "id": "BRAIN-031",
      "title": "KG: Graph Storage (NetworkX/Neo4j)",
      "description": "Store and query the knowledge graph.",
      "acceptanceCriteria": [
        "Create `GraphStore` adapter using NetworkX (in-memory) or Neo4j (persistent)",
        "Store nodes (entities) and edges (relationships)",
        "Implement `IGraphStore` port: add_entity, add_relationship, get_neighbors, find_path",
        "Support graph queries: shortest path, cliques, centrality",
        "Export graph as GraphML for visualization",
        "Test: Build character relationship graph and query it"
      ],
      "priority": 31,
      "passes": false,
      "effort": "high",
      "dependencies": [
        "BRAIN-029"
      ]
    },
    {
      "id": "BRAIN-032",
      "title": "KG: Graph-Based Context Retrieval",
      "description": "Enhance RAG with graph traversal.",
      "acceptanceCriteria": [
        "Create `GraphRetrievalService` combining vector + graph search",
        "For each retrieved chunk, fetch related entities from graph",
        "Expand context by including entity descriptions and relationships",
        "Implement 'explain' mode showing reasoning path",
        "Cache frequently accessed graph queries",
        "Test: Query shows not just matching text but connected entities"
      ],
      "priority": 32,
      "passes": false,
      "effort": "high",
      "dependencies": [
        "BRAIN-031"
      ]
    },
    {
      "id": "BRAIN-033",
      "title": "Frontend: Brain Settings",
      "description": "Configure AI Brain settings.",
      "acceptanceCriteria": [
        "Create `/brain/settings` page",
        "UI: Input fields for API Keys (OpenAI, Anthropic, Gemini) with visibility toggle",
        "UI: Model selector dropdown for each task type (Creative, Logical, Fast)",
        "UI: RAG settings (chunk size, number of chunks, hybrid search weight)",
        "UI: Knowledge base status (total entries, last sync)",
        "Settings persist to backend with encryption",
        "Test: Configure API key and verify connection"
      ],
      "priority": 33,
      "passes": false,
      "effort": "medium",
      "dependencies": [
        "BRAIN-023"
      ]
    },
    {
      "id": "BRAIN-034",
      "title": "Service: Token Usage Tracker",
      "description": "Monitor AI usage and costs.",
      "acceptanceCriteria": [
        "Implement `TokenTracker` middleware/decorator for all LLM calls",
        "Log: input_tokens, output_tokens, model, cost, timestamp, user_id",
        "Store stats in database for aggregation",
        "Support per-workspace and global tracking",
        "Real-time usage counter in UI",
        "Alert system for budget thresholds",
        "Test: Verify counting logic matches tiktoken"
      ],
      "priority": 34,
      "passes": false,
      "effort": "medium",
      "dependencies": [
        "BRAIN-028"
      ]
    },
    {
      "id": "BRAIN-035",
      "title": "Frontend: Cost Dashboard",
      "description": "Visualize AI usage and costs.",
      "acceptanceCriteria": [
        "Add 'Usage' tab to Brain Settings",
        "Chart: Tokens used over time (line chart)",
        "Chart: Cost per model type (bar chart)",
        "Stats: Total tokens, total cost, requests per day",
        "Model comparison table (cost per 1M tokens)",
        "Date range filter for analytics",
        "Export usage report as CSV",
        "Test: Display mock usage data"
      ],
      "priority": 35,
      "passes": false,
      "effort": "medium",
      "dependencies": [
        "BRAIN-034"
      ]
    },
    {
      "id": "BRAIN-036",
      "title": "UX: Context Inspector",
      "description": "Debug what the AI sees during generation.",
      "acceptanceCriteria": [
        "Add 'View AI Context' button in Director scene editor",
        "Panel shows: Retrieved chunks with sources, relevance scores, token count",
        "Highlight which chunks were actually used in generation",
        "Allow manual chunk selection for regeneration",
        "Show total context window usage vs limit",
        "Test: Inspect context for a scene generation"
      ],
      "priority": 36,
      "passes": false,
      "effort": "medium",
      "dependencies": [
        "BRAIN-007"
      ]
    },
    {
      "id": "BRAIN-037",
      "title": "Feature: Chat with Story",
      "description": "Ask questions about your novel.",
      "acceptanceCriteria": [
        "Create `ChatInterface` component (floating bottom-right widget)",
        "Backend: POST /api/brain/chat endpoint using RAG",
        "Support conversational context (multi-turn chat)",
        "Questions like: 'Who killed the king?', 'List all scenes in Chapter 1'",
        "Stream responses for better UX",
        "Chat history persistence",
        "Test: Ask question and verify answer uses RAG"
      ],
      "priority": 37,
      "passes": false,
      "effort": "high",
      "dependencies": [
        "BRAIN-006"
      ]
    },
    {
      "id": "BRAIN-038",
      "title": "Backend: Smart Tagging Service",
      "description": "Auto-organize content with tags.",
      "acceptanceCriteria": [
        "Create service to auto-generate tags for Lore/Scenes using LLM",
        "Tags: genre, mood, themes, characters_present, locations",
        "Trigger: On creation/update of content",
        "Store tags in metadata for filtering",
        "Allow manual tag override",
        "Test: Create scene and verify auto-generated tags"
      ],
      "priority": 38,
      "passes": false,
      "effort": "low"
    },
    {
      "id": "BRAIN-039",
      "title": "RAG: Automatic Chunking Strategy",
      "description": "Intelligently chunk content based on structure.",
      "acceptanceCriteria": [
        "Implement multiple chunking strategies: Fixed, Sentence, Paragraph, Semantic",
        "Auto-detect best strategy based on content type",
        "For scenes: chunk by beat/section",
        "For character sheets: chunk by attribute group",
        "Maintain narrative flow within chunks",
        "Configurable overlap size",
        "Test: Chunk a scene and verify semantic coherence"
      ],
      "priority": 39,
      "passes": false,
      "effort": "medium",
      "dependencies": [
        "BRAIN-004"
      ]
    },
    {
      "id": "BRAIN-040",
      "title": "E2E: The Brain Test",
      "description": "Verify complete RAG loop end-to-end.",
      "acceptanceCriteria": [
        "Create `tests/e2e/brain-rag.spec.ts` Playwright test",
        "Flow: Create Lore Entry -> Wait for Ingestion -> Chat with Story -> Verify Answer contains Lore content",
        "Test hybrid search: Create character with trait, search by trait",
        "Test citations: Verify sources are correctly attributed",
        "Test multi-hop: Query requiring relationship traversal",
        "Run `npm run test:e2e` and ensure all pass"
      ],
      "priority": 40,
      "passes": false,
      "effort": "high",
      "dependencies": [
        "BRAIN-037"
      ]
    }
  ]
}